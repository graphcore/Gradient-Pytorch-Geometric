{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2b361bf",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af14ce5a",
   "metadata": {},
   "source": [
    "# Training a GNN to do Fraud Detection on Graphcore IPUs using your own dataset with PyTorch Geometric\n",
    "\n",
    "TODO: Everything in this section\n",
    "\n",
    "TODO: Update links:\n",
    "\n",
    "[![Run on Gradient](../../gradient-badge.svg)](https://console.paperspace.com/github/<runtime-repo>?machine=Free-IPU-POD4&container=<dockerhub-image>&file=<path-to-file-in-repo>)  [![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)\n",
    "\n",
    ">\n",
    "> We aim to have our notebook app demos to be focused on what the user is trying to\n",
    "> do. To help you do this correctly please read [our user personnas](https://graphcore.atlassian.net/wiki/spaces/PM/pages/3157131517/Notebook+personas#Ellie%3A-The-Data-Scientist%2C-Business-Analysis%2C-Consultant),\n",
    "and when in doubt ask yourself \"does that person care about this?\".\n",
    "> To support that the first paragraph will contain all the key information, to\n",
    "> help users rapidly identify if this is the right notebook for them to go\n",
    "> though, based on:\n",
    ">\n",
    "> - The task/business problem they are trying to solve,\n",
    "> - The features that are used (Focus on big picture Deep learning features - e.g.\n",
    ">  Distributed training, not I/O overlap).\n",
    ">\n",
    "> To achieve this, each notebook should start with the following 3 paragraphs\n",
    "> (detailed in the next three comments):\n",
    ">\n",
    "> - a table highlighting what we are going to do\n",
    "> - a very short intro (3-5 sentences)\n",
    "> - clear \"steps to resolution\" (bullet points stating what the user will have\n",
    ">    to do to tackle their problem on the IPU - these need to reflect the notebook,\n",
    ">    and be as simple as possible)\n",
    "> - links to additional related resources.\n",
    ">\n",
    "\n",
    "|  Domain | Tasks | Model | Datasets | Workflow |   Number of IPUs   | Execution time |\n",
    "|---------|-------|-------|----------|----------|--------------|--------------|\n",
    "|   GNNs   |  Fraud detection  | ? | ? | Training, evaluation | recommended: 16XX (min: 4X) | 20Xmn (X1h20mn)   |\n",
    "\n",
    ">\n",
    ">\n",
    "> Start with a short introduction to the notebook. [suggested 3-5 sentences]\n",
    ">\n",
    "> This intro should focus on the problem you are fixing, and not on any IPU specific\n",
    "> or framework specific features. The mindset is that anything that is non-standard\n",
    "> is a barrier to entry, and will risk the user giving up.\n",
    ">\n",
    "> This short introduction should be followed by a clear bullet point summary of\n",
    "> the steps of the demo. Each outcome should be of the form:\n",
    "> - what the user will do (active verb) [and (optionally) how they do\n",
    ">   it]. Jargon, if any, goes to the end of the bullet point.\n",
    "\n",
    "In this demo, you will learn how to:\n",
    "\n",
    "- Turn tabular transaction data into a PyTorch Geometric dataset\n",
    "- Select a model suitable for the task of predicting fraudulent transactions\n",
    "- Train the model on Graphcore IPUs\n",
    "- Run validation on the trained model\n",
    "\n",
    "This notebook assumes some familiarity with PopTorch as well as PyTorch Geometric (PyG). For additional resources please consult:\n",
    "* [PopTorch Documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/index.html)\n",
    "* [PopTorch Examples and Tutorials](https://docs.graphcore.ai/en/latest/examples.html#pytorch)\n",
    "* [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/)\n",
    "* [PopTorch Geometric Documentation](https://docs.graphcore.ai/projects/poptorch-geometric-user-guide/en/latest/index.html)\n",
    "\n",
    "[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0279f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imported python modules automatically reload when the files are changed\n",
    "# needs to be before the first import.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# TODO: remove at the end of notebook development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c91e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add gc-logger?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db890f52",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "[![Run on Gradient](../../gradient-badge.svg)](TODO)\n",
    "\n",
    "The best way to try this demo is on Paperspace Gradient's cloud IPUs. To use on other hardware\n",
    "make sure that you have the Poplar SDK enabled with the latest PopTorch Geometric installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c72d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b33a842f",
   "metadata": {},
   "source": [
    "To improve your experience we read some configuration related to the environment you are running the notebook in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965ca0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "number_of_ipus = int(os.getenv(\"NUM_AVAILABLE_IPU\", 16))\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod16\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\")\n",
    "\n",
    "# TODO Remove default\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \".\")\n",
    "checkpoint_directory = os.getenv(\"CHECKPOINT_DIR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a32779d",
   "metadata": {},
   "source": [
    "## Loading tabular data into PyTorch Geometric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32152d7e",
   "metadata": {},
   "source": [
    "### Getting the dataset\n",
    "\n",
    "TODO: Using https://www.kaggle.com/c/ieee-fraud-detection/data\n",
    "\n",
    "TODO: Run a script to download and tidy data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a97bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import IeeeFraudDetectionDataset\n",
    "\n",
    "dataset = IeeeFraudDetectionDataset(dataset_directory)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c425d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1719)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98db4ad9",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35096262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import networkx as nx\n",
    "#from matplotlib import pyplot as plt\n",
    "#from torch_geometric.utils import to_networkx\n",
    "#\n",
    "## Convert to homogeneous\n",
    "#data_homogeneous = data.to_homogeneous()\n",
    "#g = to_networkx(data_homogeneous)\n",
    "## Use node types as colour map\n",
    "#colour_map = data_homogeneous.node_type\n",
    "#\n",
    "## TODO: This maybe?\n",
    "### Get labels\n",
    "##labels = {str(idx): val for idx, val in enumerate(data_homogeneous.y)}\n",
    "#\n",
    "## Plot the graph\n",
    "#nx.draw(g, node_color=colour_map, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "307a6822",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "703d35ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mtransaction\u001b[0m={\n",
       "    num_nodes=1000,\n",
       "    x=[1000, 963],\n",
       "    y=[1000]\n",
       "  },\n",
       "  \u001b[1mcard1\u001b[0m={\n",
       "    num_nodes=415,\n",
       "    x=[415, 1]\n",
       "  },\n",
       "  \u001b[1mcard2\u001b[0m={\n",
       "    num_nodes=132,\n",
       "    x=[132, 1]\n",
       "  },\n",
       "  \u001b[1mcard3\u001b[0m={\n",
       "    num_nodes=16,\n",
       "    x=[16, 1]\n",
       "  },\n",
       "  \u001b[1mcard4\u001b[0m={\n",
       "    num_nodes=4,\n",
       "    x=[4, 1]\n",
       "  },\n",
       "  \u001b[1mcard5\u001b[0m={\n",
       "    num_nodes=35,\n",
       "    x=[35, 1]\n",
       "  },\n",
       "  \u001b[1mcard6\u001b[0m={\n",
       "    num_nodes=2,\n",
       "    x=[2, 1]\n",
       "  },\n",
       "  \u001b[1mProductCD\u001b[0m={\n",
       "    num_nodes=4,\n",
       "    x=[4, 1]\n",
       "  },\n",
       "  \u001b[1maddr1\u001b[0m={\n",
       "    num_nodes=51,\n",
       "    x=[51, 1]\n",
       "  },\n",
       "  \u001b[1maddr2\u001b[0m={\n",
       "    num_nodes=2,\n",
       "    x=[2, 1]\n",
       "  },\n",
       "  \u001b[1mP_emaildomain\u001b[0m={\n",
       "    num_nodes=32,\n",
       "    x=[32, 1]\n",
       "  },\n",
       "  \u001b[1mR_emaildomain\u001b[0m={\n",
       "    num_nodes=26,\n",
       "    x=[26, 1]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card1)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card2)\u001b[0m={ edge_index=[2, 992] },\n",
       "  \u001b[1m(transaction, to, card3)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card4)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card5)\u001b[0m={ edge_index=[2, 995] },\n",
       "  \u001b[1m(transaction, to, card6)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, ProductCD)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, addr1)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(transaction, to, addr2)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(transaction, to, P_emaildomain)\u001b[0m={ edge_index=[2, 883] },\n",
       "  \u001b[1m(transaction, to, R_emaildomain)\u001b[0m={ edge_index=[2, 727] },\n",
       "  \u001b[1m(card1, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card2, rev_to, transaction)\u001b[0m={ edge_index=[2, 992] },\n",
       "  \u001b[1m(card3, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card4, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card5, rev_to, transaction)\u001b[0m={ edge_index=[2, 995] },\n",
       "  \u001b[1m(card6, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(ProductCD, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(addr1, rev_to, transaction)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(addr2, rev_to, transaction)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(P_emaildomain, rev_to, transaction)\u001b[0m={ edge_index=[2, 883] },\n",
       "  \u001b[1m(R_emaildomain, rev_to, transaction)\u001b[0m={ edge_index=[2, 727] }\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "013f715f",
   "metadata": {},
   "source": [
    "### Create dataset splits\n",
    "\n",
    "TODO: We sort by time above and then select those from more recent as the validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6da2debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training nodes: 800\n",
      "Number of validation nodes: 200\n"
     ]
    }
   ],
   "source": [
    "num_nodes_train = int(0.8 * data[\"transaction\"].num_nodes)\n",
    "data[\"transaction\"].train_mask = torch.zeros(data[\"transaction\"].num_nodes, dtype=bool)\n",
    "data[\"transaction\"].train_mask[:num_nodes_train] = True\n",
    "data[\"transaction\"].val_mask = torch.zeros(data[\"transaction\"].num_nodes, dtype=bool)\n",
    "data[\"transaction\"].val_mask[num_nodes_train:] = True\n",
    "\n",
    "print(f\"Number of training nodes: {data['transaction'].train_mask.sum()}\")\n",
    "print(f\"Number of validation nodes: {data['transaction'].val_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "786779f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mtransaction\u001b[0m={\n",
       "    num_nodes=1000,\n",
       "    x=[1000, 963],\n",
       "    y=[1000],\n",
       "    train_mask=[1000],\n",
       "    val_mask=[1000]\n",
       "  },\n",
       "  \u001b[1mcard1\u001b[0m={\n",
       "    num_nodes=415,\n",
       "    x=[415, 1]\n",
       "  },\n",
       "  \u001b[1mcard2\u001b[0m={\n",
       "    num_nodes=132,\n",
       "    x=[132, 1]\n",
       "  },\n",
       "  \u001b[1mcard3\u001b[0m={\n",
       "    num_nodes=16,\n",
       "    x=[16, 1]\n",
       "  },\n",
       "  \u001b[1mcard4\u001b[0m={\n",
       "    num_nodes=4,\n",
       "    x=[4, 1]\n",
       "  },\n",
       "  \u001b[1mcard5\u001b[0m={\n",
       "    num_nodes=35,\n",
       "    x=[35, 1]\n",
       "  },\n",
       "  \u001b[1mcard6\u001b[0m={\n",
       "    num_nodes=2,\n",
       "    x=[2, 1]\n",
       "  },\n",
       "  \u001b[1mProductCD\u001b[0m={\n",
       "    num_nodes=4,\n",
       "    x=[4, 1]\n",
       "  },\n",
       "  \u001b[1maddr1\u001b[0m={\n",
       "    num_nodes=51,\n",
       "    x=[51, 1]\n",
       "  },\n",
       "  \u001b[1maddr2\u001b[0m={\n",
       "    num_nodes=2,\n",
       "    x=[2, 1]\n",
       "  },\n",
       "  \u001b[1mP_emaildomain\u001b[0m={\n",
       "    num_nodes=32,\n",
       "    x=[32, 1]\n",
       "  },\n",
       "  \u001b[1mR_emaildomain\u001b[0m={\n",
       "    num_nodes=26,\n",
       "    x=[26, 1]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card1)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card2)\u001b[0m={ edge_index=[2, 992] },\n",
       "  \u001b[1m(transaction, to, card3)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card4)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, card5)\u001b[0m={ edge_index=[2, 995] },\n",
       "  \u001b[1m(transaction, to, card6)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, ProductCD)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(transaction, to, addr1)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(transaction, to, addr2)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(transaction, to, P_emaildomain)\u001b[0m={ edge_index=[2, 883] },\n",
       "  \u001b[1m(transaction, to, R_emaildomain)\u001b[0m={ edge_index=[2, 727] },\n",
       "  \u001b[1m(card1, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card2, rev_to, transaction)\u001b[0m={ edge_index=[2, 992] },\n",
       "  \u001b[1m(card3, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card4, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(card5, rev_to, transaction)\u001b[0m={ edge_index=[2, 995] },\n",
       "  \u001b[1m(card6, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(ProductCD, rev_to, transaction)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(addr1, rev_to, transaction)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(addr2, rev_to, transaction)\u001b[0m={ edge_index=[2, 658] },\n",
       "  \u001b[1m(P_emaildomain, rev_to, transaction)\u001b[0m={ edge_index=[2, 883] },\n",
       "  \u001b[1m(R_emaildomain, rev_to, transaction)\u001b[0m={ edge_index=[2, 727] }\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46c63c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fraud_train = data[\"transaction\"].y[data[\"transaction\"].train_mask].sum()\n",
    "num_total_train = len(data[\"transaction\"].train_mask)\n",
    "num_fraud_val = data[\"transaction\"].y[data[\"transaction\"].val_mask].sum()\n",
    "num_total_val = len(data[\"transaction\"].val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eab9a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_fraud_train = 3.800000%\n",
      "percentage_fraud_val = 1.100000%\n"
     ]
    }
   ],
   "source": [
    "# Number of fraud transactions\n",
    "percentage_fraud_train = num_fraud_train / num_total_train\n",
    "percentage_fraud_val = num_fraud_val / num_total_val\n",
    "print(f\"{percentage_fraud_train = :%}\")\n",
    "print(f\"{percentage_fraud_val = :%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3555f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5197505354881287, 13.1578950881958)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to set a class weight\n",
    "class_weight = (\n",
    "    (num_total_train / (2 * (num_total_train - num_fraud_train))).item(),\n",
    "    (num_total_train / (2 * num_fraud_train)).item())\n",
    "class_weight "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcda1f0b",
   "metadata": {},
   "source": [
    "## Dataloading\n",
    "\n",
    "TODO: Is graph too large that need to do some sampling - neighbour sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "251da6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/adams/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:58: UserWarning: Using '{self.__class__.__name__}' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "batch_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * num_layers,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('transaction', data['transaction'].train_mask),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86ff2af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<poptorch_geometric.fixed_size_options.FixedSizeOptions at 0x7f2660ecf550>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from poptorch_geometric import FixedSizeOptions\n",
    "\n",
    "# TODO: Use this\n",
    "# fixed_size_options = FixedSizeOptions.from_loader(train_loader)\n",
    "fixed_size_options = FixedSizeOptions(\n",
    "    num_nodes=2000,\n",
    "    num_edges=1000,\n",
    ")\n",
    "\n",
    "fixed_size_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59150a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from draft_fixed_size_neighbour_loader import FixedSizeNeighborLoader\n",
    "\n",
    "train_loader_ipu = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * num_layers,\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('transaction', data['transaction'].train_mask),\n",
    "    exclude_keys=(\"batch_size\",),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "255e188b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroDataBatch(\n",
       "  graphs_mask=[2],\n",
       "  num_nodes=24000,\n",
       "  num_edges=22000,\n",
       "  \u001b[1mtransaction\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 963],\n",
       "    y=[2000],\n",
       "    train_mask=[2000],\n",
       "    val_mask=[2000],\n",
       "    n_id=[2000],\n",
       "    input_id=[1326],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard1\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard2\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard3\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard4\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard5\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mcard6\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mProductCD\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1maddr1\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1maddr2\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mP_emaildomain\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1mR_emaildomain\u001b[0m={\n",
       "    num_nodes=2000,\n",
       "    x=[2000, 1],\n",
       "    n_id=[2000],\n",
       "    batch=[2000],\n",
       "    ptr=[3],\n",
       "    nodes_mask=[2000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card1)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card2)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card3)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card4)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card5)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, card6)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, ProductCD)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, addr1)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, addr2)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, P_emaildomain)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(transaction, to, R_emaildomain)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card1, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card2, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card3, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card4, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card5, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(card6, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(ProductCD, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(addr1, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(addr2, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(P_emaildomain, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  },\n",
       "  \u001b[1m(R_emaildomain, rev_to, transaction)\u001b[0m={\n",
       "    edge_index=[2, 1000],\n",
       "    e_id=[1000],\n",
       "    edges_mask=[1000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader_ipu))\n",
    "sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ae4b014",
   "metadata": {},
   "source": [
    "## Picking the right model\n",
    "\n",
    "TODO: Describe the task\n",
    "\n",
    "TODO: Describe different relations type - want something that can do different relations (heterogeneous graph) - RGCN could be a sensible choice\n",
    "    - but requires weights for every relation type - we have 11 relation types so might be ok\n",
    "\n",
    "TODO: Try CompGCN\n",
    "    - Only requires 3 weights - in, out, self loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b037f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Linear, SAGEConv, to_hetero\n",
    "\n",
    "import poptorch\n",
    "\n",
    "# TODO: Include num layers?\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hetero_gnn,\n",
    "                 embedding_size,\n",
    "                 out_channels,\n",
    "                 class_weight=None,\n",
    "                 batch_size=None):\n",
    "        super().__init__()\n",
    "        self.hetero_gnn = hetero_gnn\n",
    "        self.embedding = nn.ModuleDict({\n",
    "            node_type: nn.Embedding(data[node_type].num_nodes, embedding_size)\n",
    "            for node_type in data.node_types\n",
    "            if node_type != \"transaction\"\n",
    "        })\n",
    "        self.linear = Linear(-1, out_channels)\n",
    "        self.full_batch = (batch_size is None)\n",
    "        self.batch_size = batch_size\n",
    "        self.class_weight = class_weight\n",
    "\n",
    "    def forward(self,\n",
    "                x_dict,\n",
    "                edge_index_dict,\n",
    "                n_id_dict=None,\n",
    "                target=None,\n",
    "                mask=None):\n",
    "        for _, _, node_type in edge_index_dict.keys():\n",
    "            if node_type != \"transaction\":\n",
    "                if self.full_batch:\n",
    "                    x_dict[node_type] = self.embedding[node_type].weight\n",
    "                else:\n",
    "                    assert n_id_dict is not None, (\n",
    "                        \"If using a sampled batch, `n_id_dict` must\"\n",
    "                        \" be provided.\")\n",
    "                    x_dict[node_type] = self.embedding[node_type](n_id_dict[node_type])\n",
    "\n",
    "        x_dict = self.hetero_gnn(x_dict, edge_index_dict)\n",
    "        out = self.linear(x_dict['transaction'])\n",
    "        if self.training:\n",
    "            if self.full_batch:\n",
    "                loss = F.cross_entropy(out, target, reduction='none')\n",
    "\n",
    "                if self.class_weight is not None:\n",
    "                    class_weight = target * self.class_weight[1] + (1 - target) * self.class_weight[0]\n",
    "                    class_weight *= mask\n",
    "                    class_weight *= (mask.sum() / class_weight.sum())\n",
    "                    loss *= class_weight\n",
    "\n",
    "                loss *= mask\n",
    "                loss = loss.sum() / mask.sum()\n",
    "                loss = poptorch.identity_loss(loss, reduction='none')\n",
    "            else:\n",
    "                out = out[:self.batch_size]\n",
    "                target = target[:self.batch_size]\n",
    "                # TODO: Use nodes_mask here\n",
    "\n",
    "                loss = F.cross_entropy(out, target, reduction='none')\n",
    "\n",
    "                if self.class_weight is not None:\n",
    "                    class_weight = target * self.class_weight[1] + (1 - target) * self.class_weight[0]\n",
    "                    class_weight *= (self.batch_size / class_weight.sum())\n",
    "                    loss *= class_weight\n",
    "                loss = poptorch.identity_loss(loss, reduction='mean')\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "\n",
    "model = GNN(hidden_channels=64)\n",
    "model = to_hetero(model, data.metadata(), aggr=\"sum\")\n",
    "model = Model(model,\n",
    "              embedding_size=128,\n",
    "              out_channels=2,\n",
    "              class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f37186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1387, -0.7291],\n",
       "        [-0.9554, -0.1080],\n",
       "        [-1.7077,  0.2353],\n",
       "        ...,\n",
       "        [ 0.9946, -0.0627],\n",
       "        [-0.1329, -1.5922],\n",
       "        [ 0.1098, -2.2154]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out_cpu, loss = model(data.x_dict,\n",
    "                          data.edge_index_dict,\n",
    "                          target=data[\"transaction\"].y,\n",
    "                          mask=data[\"transaction\"].train_mask)\n",
    "out_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5905665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:17:45.022] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[11:17:45.023] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "Graph compilation: 100%|██████████| 100/100 [01:09<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1387, -0.7291],\n",
       "        [-0.9554, -0.1080],\n",
       "        [-1.7077,  0.2353],\n",
       "        ...,\n",
       "        [ 0.9946, -0.0627],\n",
       "        [-0.1329, -1.5922],\n",
       "        [ 0.1098, -2.2154]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import poptorch\n",
    "\n",
    "model.eval()\n",
    "inf_model = poptorch.inferenceModel(model)\n",
    "out_ipu = inf_model(data.x_dict,\n",
    "                    data.edge_index_dict,\n",
    "                    target=data[\"transaction\"].y,\n",
    "                    mask=data[\"transaction\"].train_mask)\n",
    "out_ipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c964c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(out_cpu, out_ipu, rtol=1e-05, atol=1e-05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ee6edb",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "TODO: Train the model in the normal way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98b652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "embedding_size = 128\n",
    "hidden_channels = 16\n",
    "log_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f68c1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(hidden_channels=hidden_channels)\n",
    "model = to_hetero(model, data.metadata(), aggr=\"sum\")\n",
    "model = Model(model,\n",
    "              embedding_size=embedding_size,\n",
    "              #class_weight=class_weight,\n",
    "              out_channels=2,\n",
    "              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1018781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Options(replication_factor=1, input_group_size=1, input_cgt=<CommGroupType.Consecutive: 1>, broadcast_buffers=True, device_iterations=1, log_dir='.', max_repeat_logs=4, auto_round_num_ipus=False, anchored_tensors={}, output_mode=4, output_return_period=1, connection_type=0, sync_pattern=0, available_memory_proportion={}, Distributed=_DistributedOptions(num_distributed_processes=1, distributed_process_id=0, ipuof_configs={}, _gcd_mappings={}, _warnings={}, _warnings_disabled=set(), _is_frozen=False), Jit=_JitOptions(, _warnings={}, _warnings_disabled=set(), _is_frozen=False), Precision=_PrecisionOptions(, _popart_options=_PopartOptions(instrumentWithHardwareCycleCounter=False, rearrangeAnchorsOnHost=False, cachePath='/tmp/exe_cache/', enableEngineCaching=True), _warnings={}, _warnings_disabled=set(), _is_frozen=False), TensorLocations=_TensorLocationOptions(, _warnings={}, _warnings_disabled=set(), _is_frozen=False), Training=_TrainingOptions(gradient_accumulation=1, accumulation_and_replication_reduction_type=<ReductionType.Mean: 1>, meanAccumulationAndReplicationReductionStrategy=<MeanReductionStrategy.Post: 1>, _popart_options=_PopartOptions(instrumentWithHardwareCycleCounter=False, rearrangeAnchorsOnHost=False, cachePath='/tmp/exe_cache/', enableEngineCaching=True), _warnings={}, _warnings_disabled=set(), _is_frozen=False), _Popart=_PopartOptions(instrumentWithHardwareCycleCounter=False, rearrangeAnchorsOnHost=False, cachePath='/tmp/exe_cache/', enableEngineCaching=True))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poptorch_options = poptorch.Options()\n",
    "poptorch_options.enableExecutableCaching(executable_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ec4ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_ipu = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * num_layers,\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    batch_size=batch_size,\n",
    "    input_nodes=('transaction', data['transaction'].train_mask),\n",
    "    exclude_keys=(\"batch_size\",),\n",
    "    options=poptorch_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de040594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8612)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader_ipu))\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out_cpu, loss = model(sample.x_dict,\n",
    "                          sample.edge_index_dict,\n",
    "                          n_id_dict=sample.n_id_dict,\n",
    "                          target=sample[\"transaction\"].y)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "45cecaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:54:57.032] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[12:54:57.033] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[12:54:57.033] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "In poptorch/popart_compiler/source/CompilerImpl.cpp:725: 'poptorch_cpp_error': Failed to acquire 1 IPU(s)\nError raised in:\n  [0] Compiler::initSession\n  [1] LowerToPopart::compile\n  [2] compileWithManualTracing\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-9a67006486d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader_ipu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         out, loss = training_model(batch.x_dict,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                    \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                    \u001b[0mn_id_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_id_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misCompiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/poptorch/_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracepoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(self, in_tensors)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# trigger the compilation process in all the other processes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misCompiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compileWithDispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensors_trace_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;31m# Load the engine and connect the streams in all the processes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/poptorch/_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOnExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_compileWithDispatch\u001b[0;34m(self, in_tensors, executable_filename)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;31m# Compile the captured graph using PopART.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 executable = poptorch_core.compileWithManualTracing(\n\u001b[0m\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: In poptorch/popart_compiler/source/CompilerImpl.cpp:725: 'poptorch_cpp_error': Failed to acquire 1 IPU(s)\nError raised in:\n  [0] Compiler::initSession\n  [1] LowerToPopart::compile\n  [2] compileWithManualTracing\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = poptorch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_model = poptorch.trainingModel(model, optimizer=optimizer, options=poptorch_options)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in train_loader_ipu:\n",
    "        out, loss = training_model(batch.x_dict,\n",
    "                                   batch.edge_index_dict,\n",
    "                                   n_id_dict=batch.n_id_dict,\n",
    "                                   target=batch['transaction'].y)\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    if epoch % log_freq == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss / total_examples}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c127b86",
   "metadata": {},
   "source": [
    "## Validating our trained model\n",
    "\n",
    "TODO: Validate the model in the normal way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ed8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:50:42.024] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[12:50:42.026] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "/nethome/adams/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Graph compilation: 100%|██████████| 100/100 [00:05<00:00]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Should I sample?\n",
    "\n",
    "model.eval()\n",
    "model.full_batch = True\n",
    "inference_model = poptorch.inferenceModel(model, options=poptorch_options)\n",
    "\n",
    "out = inference_model(data.x_dict,\n",
    "                      data.edge_index_dict,\n",
    "                      target=data['transaction'].y,\n",
    "                      mask=data['transaction'].val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.Softmax(dim=-1)(out)\n",
    "y_pred = y_pred[:, -1]\n",
    "y_pred = y_pred > 0.5\n",
    "y_pred = y_pred[data['transaction'].val_mask]\n",
    "y_true = data['transaction'].y[data['transaction'].val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d54c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8850)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    correct = y_pred.eq(y_true).sum()\n",
    "    return correct / len(y_pred)\n",
    "\n",
    "accuracy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(12), tensor(177), tensor(11))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_confusion_matrix(y_pred, y_true):\n",
    "    y_pred = y_pred.bool()\n",
    "    y_true = y_true.bool()\n",
    "    true_positives = (y_pred * y_true).sum()\n",
    "    false_positives = (y_pred * ~y_true).sum()\n",
    "    true_negatives = (~y_pred * ~y_true).sum()\n",
    "    false_negatives = (~y_pred * y_true).sum()\n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "true_pos, false_pos, true_neg, false_neg = get_confusion_matrix(y_pred, y_true)\n",
    "true_pos, false_pos, true_neg, false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.0635))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rates(true_pos, false_pos, true_neg, false_neg):\n",
    "    true_pos_rate = true_pos / (true_pos + false_neg)\n",
    "    false_pos_rate = false_pos / (false_pos + true_neg)\n",
    "    return true_pos_rate, false_pos_rate\n",
    "\n",
    "get_rates(true_pos, false_pos, true_neg, false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision(true_pos, false_pos):\n",
    "    return true_pos / (true_pos + false_pos)\n",
    "\n",
    "def recall(true_pos, false_neg):\n",
    "    return true_pos / (true_pos + false_neg)\n",
    "\n",
    "precision(true_pos, false_pos), recall(true_pos, false_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13a8d042",
   "metadata": {},
   "source": [
    "### With threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f646b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "for threshold in np.arange(0.0, 1.1, 0.1):\n",
    "    y_pred = nn.Softmax(dim=-1)(out)\n",
    "    y_pred = y_pred[:, -1]\n",
    "    y_pred = y_pred > threshold\n",
    "    y_pred = y_pred[data['transaction'].val_mask]\n",
    "    y_true = data['transaction'].y[data['transaction'].val_mask]\n",
    "    results.append((threshold, *get_rates(*get_confusion_matrix(y_pred, y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "deff7167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, tensor(1.), tensor(1.)),\n",
       " (0.1, tensor(0.0909), tensor(0.0847)),\n",
       " (0.2, tensor(0.), tensor(0.0794)),\n",
       " (0.30000000000000004, tensor(0.), tensor(0.0794)),\n",
       " (0.4, tensor(0.), tensor(0.0741)),\n",
       " (0.5, tensor(0.), tensor(0.0635)),\n",
       " (0.6000000000000001, tensor(0.), tensor(0.0582)),\n",
       " (0.7000000000000001, tensor(0.), tensor(0.0582)),\n",
       " (0.8, tensor(0.), tensor(0.0529)),\n",
       " (0.9, tensor(0.), tensor(0.0476)),\n",
       " (1.0, tensor(0.), tensor(0.))]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbb69bd4",
   "metadata": {},
   "source": [
    "## Explainability\n",
    "\n",
    "TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ece4041",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "> The conclusion to your demo should:\n",
    ">\n",
    "> - summarise the main steps that were taken in the demo making clear what\n",
    ">  your user got to do (similar to steps at the start but more\n",
    ">  specific, you can link a specific feature/method/class to achieving a specific\n",
    ">  outcome). (short paragraph: 3-6 sentences)\n",
    "> - provide resources to go further: these can be links to other tutorials, to\n",
    ">  documentation, to code examples in the public_examples repo, tech notes, deployments,\n",
    ">  etc... (2-4 suggestions)\n",
    ">\n",
    "> For pointing users to notebooks in the same runtime, point the user to where the file is rather than a link. For example: please see our tutorial, `<folder_name>/<notebook_name>.ipynb`. For relative links the paperspace platform will download the file locally if the machine is running and if the machine is not running will 404. For full path links a new window is opened."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.2.0+1277_poptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "14ed74787bcb3a85d33b99e2a461605961fba8ba6d9ddfcf06c9973f1378dba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
