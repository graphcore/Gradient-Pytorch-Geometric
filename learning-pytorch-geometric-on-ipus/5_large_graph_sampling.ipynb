{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2b361bf",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1847b0b2",
   "metadata": {},
   "source": [
    "# Sampling large graphs on IPUs using PyTorch Geometric\n",
    "\n",
    "\n",
    "\n",
    "[![Run on Gradient](../../gradient-badge.svg)](https://console.paperspace.com/github/<runtime-repo>?machine=Free-IPU-POD4&container=<dockerhub-image>&file=<path-to-file-in-repo>)  [![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)\n",
    "\n",
    ">### Link for the Run on Gradient button\n",
    "\n",
    "> Once the notebook is available on Paperspace Gradient we like to have a \"Run on Gradient\" button. The link for the button needs to be configured. The example above shows the convention for how to form the link. \n",
    "\n",
    "> - The SVG image file for the button should be a local file in the repo (as shown in the example above). You can also use the [image file on Paperspace](https://assets.paperspace.io/img/gradient-badge.svg) but this is not reliable as Github's caching occasionally breaks.\n",
    "> - `<runtime-repo>` represents the \"organisation/repository-name\" of the public repository that contains the notebook.\n",
    "> - `<dockerhub-image>` is the name and tag of a public Docker Hub container.\n",
    "> - `<path-to-file-in-repo>` is the location of the notebook inside the repo starting with a leading `/`.\n",
    ">\n",
    "> Note the part after the `?` in the link needs to be URL-encoded. You can use an online [URL encoder](https://www.urlencoder.org/) or you can use the [Paperspace link builder](https://docs.paperspace.com/gradient/notebooks/run-on-gradient/).\n",
    ">\n",
    "> Example of a fully-formed link for the \"Run on Gradient\" button:\n",
    "> https://console.paperspace.com/github/gradient-ai/Graphcore-Pytorch?machine=Free-IPU-POD4&container=graphcore/pytorch-jupyter:3.1.0-ubuntu-20.04-20230104&file=/temporal-graph-networks/Train_TGN.ipynb\n",
    "\n",
    "In the previous tutorials we have been focusing on working with datasets comprising many small graphs. For some modern applications, however, we will need to operate on larger graphs characterised by increasing number of nodes (range 10M-10B) and edges (range 100M-100B): imagine having to build a recommendation system for a social network type of input graph, which can be consituted by a huge number of users (nodes) and relationships (edges). Mention OGB benchmarks as well? \n",
    "\n",
    "We might think of two routes to approach large graph problems:\n",
    "- full batch training: this is the approach we have been using in [Tutorial 2](TODO add link) when working with a single, relatively small graph. The aim is to generate embeddings for all the nodes at the same time: this entails keeping in memory the entire graph as well as all the node embeddings. If the size of the computational graph increases, the amount of memory required to hold graph and embeddings become challenging. \n",
    "- mini-batching: alternatively, we can sample mini-batches from the graph similarly to what we did in Tutorial 3 or 4 [TODO add links] where the dataset was a collection of many small graphs. When sampling from a larger graph, however, we need to be extra careful to reduce the chances of the sampled nodes to be isolated from each other. Should that be the case, the mini-batches would no longer be representative of the whole graph which would negatively impact our machine learning task. The need here is to engineer effective sampling methods to make sure that the message passing scheme is still effective with large graphs. \n",
    "\n",
    "In this tutorial, we will demonstrate two approaches widely used in literature to cope with increasing graph size by performing message passage over mini-batches. We will leverage the Graphcore IPU architecture, which is a very good fit for GNNs applications [TODO link blogs], and our PyTorch Geometric (PyG) integration. You will learn how to: \n",
    "- effectively cluster nodes of your input graph, then train your GNN on IPUs to classify papers from the PubMed dataset\n",
    "- sample neighbouring nodes of your input graph, then train your GNN on IPUs to (TODO link prediction task)\n",
    "\n",
    "This notebook assumes some familiarity with PopTorch as well as PyTorch Geometric (PyG). For additional resources please consult:\n",
    "- [PopTorch Documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/index.html),\n",
    "- [PopTorch Examples and Tutorials](https://docs.graphcore.ai/en/latest/examples.html#pytorch),\n",
    "- [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/),\n",
    "- [PopTorch Geometric Documentation](https://docs.graphcore.ai/projects/poptorch-geometric-user-guide/en/latest/index.html).\n",
    "\n",
    "[![Join our Slack\n",
    "Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imported python modules automatically reload when the files are changed\n",
    "# needs to be before the first import.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# TODO: remove at the end of notebook development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db890f52",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "The best way to run this demo is on Paperspace Gradient's cloud IPUs because everything is already set up for you. To run the demo using other IPU hardware, you need to have the Poplar SDK enabled and the latest PopTorch Geometric wheel installed. Refer to the [getting started guide](https://docs.graphcore.ai/en/latest/getting-started.html#getting-started) for your system for details on how to enable the Poplar SDK and install the PopTorch wheels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9927c",
   "metadata": {},
   "source": [
    "> You can install requirements directly from a notebook. You can:\n",
    ">\n",
    "> 1. Run commands by starting the line in a code cell with `!`, as shown in the first code block below. \n",
    "> 2. Install Python requirements with the `%pip` [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html).\n",
    "> \n",
    "> Use these methods to make it easier for your user to set up the environment they need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b33a842f",
   "metadata": {},
   "source": [
    "To make it easier for you to run this tutorial, we read in some configuration related to the environment you are running the notebook in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ca0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "number_of_ipus = int(os.getenv(\"NUM_AVAILABLE_IPU\", 16))\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod16\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\")\n",
    "checkpoint_directory = os.getenv(\"CHECKPOINT_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bf5f1",
   "metadata": {},
   "source": [
    "> As the notebook writer, you only need to define a variable if you intend to use the value in the rest of the notebook.\n",
    "> You can choose to use the default values of any variables if it is better for your development workflow.\n",
    "> When you write the notebook, you need to use those variables that you have defined to configure the execution.\n",
    ">\n",
    "> Note on Poplar executables: We also set the standard PyTorch, PopART and TensorFlow environment variables, so\n",
    "> if you do not customise the behaviour then you don't need to read them from the environment.\n",
    "> For more information refer to [Writing a Paperspace notebook](https://graphcore.atlassian.net/wiki/spaces/PM/pages/3098345498/Writing+a+Paperspace+notebook)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a32779d",
   "metadata": {},
   "source": [
    "## Clustering the computation graph for node classification\n",
    "\n",
    "The idea: we can sample the entire graph in small subgraphs that individually fit in memory and on which we can calculate layer-wise embeddings, performing message passing on one subgraph at the time.\n",
    "The subgraph should also retain the connectivity of the original graph, to achieve that we make sure that the small communities the original graph is made up of are mirrored in the subgraphs.\n",
    "\n",
    "A well known approach is Cluster-GCN (TODO link the example). The steps are:\n",
    "- pre-procesing: given a large graph, we partition it into group of nodes we name subgraphs\n",
    "- mini-batch training: we load one subgraph at the time in the device memory, apply message passing over it to compute the loss\n",
    "\n",
    "\n",
    "### Cluster-GCN in PyG on IPUs\n",
    "\n",
    "Notes:\n",
    "- in our cluster-gcn example we use Metis to do the pre-processing step. In the PyG tutorial on 'scaling GNNs' the use `ClusterData` PyG API, shall I try to use this latter to be more PyG?\n",
    "- Given a user defined `batch_size` they using `ClusterLoader` to implement the stochastic partitioning scheme. On our side, we should use `FixedSizeClusterLoader` in PopTorch Geometric to comply with AOT compilation requirement. \n",
    "- To demonstrate that using clustering does not complicate the GNN model implementation, it would then be good to re-use a GCN model like the one we defined in e.g. Tutorial 2\n",
    "\n",
    "### Training a GNN to classify papers in PubMed dataset\n",
    "\n",
    "Idea: node classification in PubMed dataset from the Planetoid node classification benchmarking suite."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e88f45",
   "metadata": {},
   "source": [
    "## Neighbourhood sampling the computation graph for link prediction\n",
    "\n",
    "### Neighbour sampling in PyG on IPUs \n",
    "\n",
    "### Training a GNN to predict XYZ in KKK dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2bae0a",
   "metadata": {},
   "source": [
    "> ### Useful tips and known challenges\n",
    ">\n",
    "> #### Working with `argparse` and command line arguments\n",
    ">\n",
    "> If you have encountered problems related to `argparse` while writing a notebook, these tips may help you resolve your problem:\n",
    "> - Try to disentangle your application from any argument parsing logic.\n",
    "> - Manually create an [`argparse.Namespace`](https://docs.python.org/3/library/argparse.html#argparse.Namespace).\n",
    "> - Define custom parsing logic in your app to detect when its running in a Jupyter Notebook, for example as shown in the [simple parsing utilities](https://github.com/graphcore/examples-utils/blob/f8673d362fdc7dc77e1fee5f77cbcd81dd9e4a2e/examples_utils/parsing/simple_parsing_tools.py#L118). \n",
    "> \n",
    "> Often with these kinds of problems, the issue is rooted in the structure of the app, so consider using the [Applications common code interface](https://graphcore.atlassian.net/wiki/spaces/PM/pages/3164995668/Making+applications+notebook+ready+RFC#Proposal) to write an app that is easier to use.\n",
    ">\n",
    "> #### Detaching from IPUs\n",
    ">\n",
    "> Notebooks continue running after the last cell has been run, so you need to make sure that all IPUs are released at the end. This ensures that other users have resources available to run their notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.isAttachedToDevice():\n",
    "model.detachFromDevice()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ece4041",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we explored the main methods to deal with large graphs that otherwise wouldn't fit in memory, using two different sampling approaches and dedicated dataloaders to optimise performance on Graphcore IPUs. While we have worked with homogeneous graphs in this tutorial, scaled up GNN problems are also very well suited to heterogeneous graphs (for example, citation graphs can be huge).\n",
    "\n",
    "TODO add more details about what we covered\n",
    "\n",
    "> This section should describe the conclusions from this notebook:\n",
    ">\n",
    "> - Summarise the main steps that were performed in the demo making it clear what\n",
    ">  your user got to do. This can be similar to the learning outcomes listed at the beginning of the notebook, but can contain more details. Try to link the specific feature, method or class that was used to achieving a specific outcome. Remember we want to highlight how we can solve the user's problems not sell a feature. (short paragraph: 3-6 sentences)\n",
    "> - Provide resources for the user's next steps. These can be links to other tutorials, to specific \n",
    ">  documentation (for example user guides, tech notes), to code examples in the public Graphcore [examples](https://github.com/graphcore/examples) repo, or to other deployments. (2-4 suggestions)\n",
    ">\n",
    "> If you want to link to a notebook in the same runtime, then point the user to the file is rather than using an explicit. For example: \"Please see our [name of tutorial] tutorial in `<folder_name>/<notebook_name>.ipynb`. For relative links, the Paperspace platform will download the file locally if the machine is running and if the machine is not running it will throw a 404 error. New windows are opened for full path links."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
