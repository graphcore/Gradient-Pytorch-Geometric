{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2b361bf",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1847b0b2",
   "metadata": {},
   "source": [
    "# Sampling large graphs on IPUs using PyTorch Geometric\n",
    "\n",
    "\n",
    "\n",
    "[![Run on Gradient](../../gradient-badge.svg)](https://console.paperspace.com/github/<runtime-repo>?machine=Free-IPU-POD4&container=<dockerhub-image>&file=<path-to-file-in-repo>)  [![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)\n",
    "\n",
    ">### Link for the Run on Gradient button\n",
    "\n",
    "> Once the notebook is available on Paperspace Gradient we like to have a \"Run on Gradient\" button. The link for the button needs to be configured. The example above shows the convention for how to form the link. \n",
    "\n",
    "> - The SVG image file for the button should be a local file in the repo (as shown in the example above). You can also use the [image file on Paperspace](https://assets.paperspace.io/img/gradient-badge.svg) but this is not reliable as Github's caching occasionally breaks.\n",
    "> - `<runtime-repo>` represents the \"organisation/repository-name\" of the public repository that contains the notebook.\n",
    "> - `<dockerhub-image>` is the name and tag of a public Docker Hub container.\n",
    "> - `<path-to-file-in-repo>` is the location of the notebook inside the repo starting with a leading `/`.\n",
    ">\n",
    "> Note the part after the `?` in the link needs to be URL-encoded. You can use an online [URL encoder](https://www.urlencoder.org/) or you can use the [Paperspace link builder](https://docs.paperspace.com/gradient/notebooks/run-on-gradient/).\n",
    ">\n",
    "> Example of a fully-formed link for the \"Run on Gradient\" button:\n",
    "> https://console.paperspace.com/github/gradient-ai/Graphcore-Pytorch?machine=Free-IPU-POD4&container=graphcore/pytorch-jupyter:3.1.0-ubuntu-20.04-20230104&file=/temporal-graph-networks/Train_TGN.ipynb\n",
    "\n",
    "In the previous tutorials we have been focusing on working with datasets comprising many small graphs. For some modern applications, however, we will need to operate on larger graphs characterised by increasing number of nodes (range 10M-10B) and edges (range 100M-100B): imagine having to build a recommendation system for a social network type of input graph, which can be consituted by a huge number of users (nodes) and relationships (edges). Mention OGB benchmarks as well? \n",
    "\n",
    "We might think of two routes to approach large graph problems:\n",
    "- full batch training: this is the approach we have been using in [Tutorial 2](TODO add link) when working with a single, relatively small graph. The aim is to generate embeddings for all the nodes at the same time: this entails keeping in memory the entire graph as well as all the node embeddings. If the size of the computational graph increases, the amount of memory required to hold graph and embeddings become challenging. \n",
    "- mini-batching: alternatively, we can sample mini-batches from the graph similarly to what we did in Tutorial 3 or 4 [TODO add links] where the dataset was a collection of many small graphs. When sampling from a larger graph, however, we need to be extra careful to reduce the chances of the sampled nodes to be isolated from each other. Should that be the case, the mini-batches would no longer be representative of the whole graph which would negatively impact our machine learning task. The need here is to engineer effective sampling methods to make sure that the message passing scheme is still effective with large graphs. \n",
    "\n",
    "In this tutorial, we will demonstrate two approaches widely used in literature to cope with increasing graph size by performing message passage over mini-batches. We will leverage the Graphcore IPU architecture, which is a very good fit for GNNs applications [TODO link blogs], and our PyTorch Geometric (PyG) integration. You will learn how to: \n",
    "- effectively cluster nodes of your input graph; \n",
    "- sample neighbouring nodes of your input graph; \n",
    "- then, for both sampling methods, train your GNN on IPUs to classify papers from the PubMed dataset.\n",
    "\n",
    "This notebook assumes some familiarity with PopTorch as well as PyTorch Geometric (PyG). For additional resources please consult:\n",
    "- [PopTorch Documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/index.html),\n",
    "- [PopTorch Examples and Tutorials](https://docs.graphcore.ai/en/latest/examples.html#pytorch),\n",
    "- [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/),\n",
    "- [PopTorch Geometric Documentation](https://docs.graphcore.ai/projects/poptorch-geometric-user-guide/en/latest/index.html).\n",
    "\n",
    "[![Join our Slack\n",
    "Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0279f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imported python modules automatically reload when the files are changed\n",
    "# needs to be before the first import.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# TODO: remove at the end of notebook development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db890f52",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "The best way to run this demo is on Paperspace Gradient's cloud IPUs because everything is already set up for you. To run the demo using other IPU hardware, you need to have the Poplar SDK enabled and the latest PopTorch Geometric wheel installed. Refer to the [getting started guide](https://docs.graphcore.ai/en/latest/getting-started.html#getting-started) for your system for details on how to enable the Poplar SDK and install the PopTorch wheels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9927c",
   "metadata": {},
   "source": [
    "> You can install requirements directly from a notebook. You can:\n",
    ">\n",
    "> 1. Run commands by starting the line in a code cell with `!`, as shown in the first code block below. \n",
    "> 2. Install Python requirements with the `%pip` [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html).\n",
    "> \n",
    "> Use these methods to make it easier for your user to set up the environment they need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c72d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b33a842f",
   "metadata": {},
   "source": [
    "To make it easier for you to run this tutorial, we read in some configuration related to the environment you are running the notebook in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965ca0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "number_of_ipus = int(os.getenv(\"NUM_AVAILABLE_IPU\", 16))\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod16\")\n",
    "executable_cache_dir = (\n",
    "    os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") \n",
    "    + \"/pyg-large-graph-sampling\"\n",
    ")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \"data\")\n",
    "checkpoint_directory = os.getenv(\"CHECKPOINT_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bf5f1",
   "metadata": {},
   "source": [
    "> As the notebook writer, you only need to define a variable if you intend to use the value in the rest of the notebook.\n",
    "> You can choose to use the default values of any variables if it is better for your development workflow.\n",
    "> When you write the notebook, you need to use those variables that you have defined to configure the execution.\n",
    ">\n",
    "> Note on Poplar executables: We also set the standard PyTorch, PopART and TensorFlow environment variables, so\n",
    "> if you do not customise the behaviour then you don't need to read them from the environment.\n",
    "> For more information refer to [Writing a Paperspace notebook](https://graphcore.atlassian.net/wiki/spaces/PM/pages/3098345498/Writing+a+Paperspace+notebook)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3da127aa",
   "metadata": {},
   "source": [
    "## Clustering the computation graph for node classification\n",
    "\n",
    "The idea: we can sample the entire graph in small subgraphs that individually fit in memory and on which we can calculate layer-wise embeddings, performing message passing on one subgraph at the time.\n",
    "The subgraph should also retain the connectivity of the original graph, to achieve that we make sure that the small communities the original graph is made up of are mirrored in the subgraphs.\n",
    "\n",
    "A well known approach is [Cluster-GCN](https://arxiv.org/abs/1905.07953). The steps are:\n",
    "- pre-procesing: given a large graph, we partition it into group of nodes we name subgraphs\n",
    "- mini-batch training: we load one subgraph at the time in the device memory, apply message passing over it to compute the loss\n",
    "\n",
    "You can also check out our dedicated Cluster-GCN example (TODO add link)\n",
    "\n",
    "### Cluster-GCN in PyG on IPUs\n",
    "\n",
    "\n",
    "\n",
    "First, let's load the `PubMed` dataset from the `Planetoid` node classification benchmarking suite and print some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8b9c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PubMed() \n",
      "Number of graphs: 1: \n",
      "Number of features: 500 \n",
      "Number of classes: 3 \n",
      "Data(x=[19717, 500], edge_index=[2, 108365], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
      "Total number of nodes: 19717\n",
      "Total number of edges: 108365\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.AddSelfLoops()])\n",
    "\n",
    "dataset = Planetoid(root=dataset_directory, name=\"PubMed\", transform=transform)\n",
    "data = dataset[0]  # Access the graph as Data object\n",
    "\n",
    "print(f\"Dataset: {dataset} \")\n",
    "print(f\"Number of graphs: {len(dataset)}: \")\n",
    "print(f\"Number of features: {dataset.num_features} \")\n",
    "print(f\"Number of classes: {dataset.num_classes} \")\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(f\"Total number of nodes: {data.num_nodes}\")\n",
    "print(f\"Total number of edges: {data.num_edges}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72793ce7",
   "metadata": {},
   "source": [
    "The dataset consists of 19717 scientific publications from the PubMed database relative to diabetes classified into one of three classes. This is not a huge dataset, but it will serve our purpose to demonstrate the sampling approaches. \n",
    "Let's now proceed with the clustering. The first step is to use `ClusterData` to partition our `Data` object into `num_clusters` clusters: under the hood it leverages the METIS algorithm to obtain the split (TODO add more info on how the METIS algo works?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b5129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been split in 100 clusters\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import ClusterData\n",
    "\n",
    "num_clusters = 100\n",
    "\n",
    "cluster_data = ClusterData(\n",
    "    data, num_parts=num_clusters, recursive=False, save_dir=dataset_directory\n",
    ")\n",
    "\n",
    "print(f\"The dataset has been split in {len(cluster_data)} clusters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6730e63",
   "metadata": {},
   "source": [
    "We can now inspect the composition of a couple of clusters, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a555d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[196, 500], y=[196], train_mask=[196], val_mask=[196], test_mask=[196], edge_index=[2, 626]),\n",
       " Data(x=[202, 500], y=[202], train_mask=[202], val_mask=[202], test_mask=[202], edge_index=[2, 706]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_data[50], cluster_data[60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f13cbeae",
   "metadata": {},
   "source": [
    "You will observe how each cluster contains a different number of nodes and edges, which we will need to keep in mind when preparing the mini-batches to feed into the IPU. The IPU relies on Ahead-Of-Time compilation hence it needs the input tensors to be fixed sizes. The mini-batches that we will load onto the IPU will be the result of combining clusters together, hence each mini-batch will have a different size.  We need to make sure that the mini-batches are fixed in size so they can be loaded correctly into the IPU. \n",
    "\n",
    "We can leverage the `Summary` API in PyG to find out the maximum number of nodes and edges in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923c46ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterData (#graphs=100):\n",
       "+------------+----------+----------+\n",
       "|            |   #nodes |   #edges |\n",
       "|------------+----------+----------|\n",
       "| mean       |    197.2 |    803.7 |\n",
       "| std        |      4.7 |    199.2 |\n",
       "| min        |    191   |    581   |\n",
       "| quantile25 |    192.8 |    666.5 |\n",
       "| median     |    197   |    740   |\n",
       "| quantile75 |    202   |    858   |\n",
       "| max        |    203   |   1497   |\n",
       "+------------+----------+----------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data.summary import Summary\n",
    "\n",
    "cluster_summary = Summary.from_dataset(cluster_data)\n",
    "cluster_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "220a759d",
   "metadata": {},
   "source": [
    "We can use this information to calculate the maximum number of nodes that we would like to have in each mini-batch, which will also be consistent across mini-batches. To do so we also need to choose how many clusters we'd like to have in each mini-batch (equivalent to choosing a `batch_size` in Tutorial 3), let's set it to 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d52167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_per_batch = 10 # batch_size\n",
    "\n",
    "max_num_nodes_per_cluster = int(cluster_summary.num_nodes.max)\n",
    "max_nodes_per_batch = max_num_nodes_per_cluster * clusters_per_batch + 1\n",
    "\n",
    "max_nodes_per_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "797e59f8",
   "metadata": {},
   "source": [
    "Let's keep in mind we will also need to number of edges to be consistent across mini-batches to work with fixed sizes on the IPU: this means we will need to apply some padding to the number of edges. In the code cell above we added one dummy node to the maximum number of nodes in each mini-batch so that we can use it to link all the padded edges to it as self-loops. Now let's calculate the number of edges: we need to approximate it using the average statics printed above, to which we will add its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b1f91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_edges_per_batch = int(cluster_summary.num_edges.mean) + int(\n",
    "    cluster_summary.num_edges.std\n",
    ")\n",
    "max_edges_per_batch *= clusters_per_batch\n",
    "max_edges_per_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3edafb",
   "metadata": {},
   "source": [
    "You might already be familiar with the PyG `ClusterLoader` to implement the stochastic partitioning scheme in CLuster-GCN given a user defined `batch_size` . To comply with the AOT compilation requirement on IPUs we will use instead `FixedSizeClusterLoader` from PopTorch Geometric, where we can specify the number of nodes and edges to be fixed in every mini-batch and equal to the quantities calculated in the previous two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4665571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch\n",
    "from poptorch_geometric.cluster_loader import FixedSizeClusterLoader\n",
    "\n",
    "train_dataloader = FixedSizeClusterLoader(\n",
    "    cluster_data,\n",
    "    batch_size=clusters_per_batch,\n",
    "    num_nodes=max_nodes_per_batch,\n",
    "    collater_args=dict(num_edges=max_edges_per_batch, trim_edges=True),\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ae8a44",
   "metadata": {},
   "source": [
    "Let's now inspect a few mini-batches loaded by the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aae8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next(train_dataloader_iter) = DataBatch(x=[610, 500], edge_index=[2, 3006], y=[610], batch=[610], ptr=[3], test_mask=[610], train_mask=[610], val_mask=[610], num_nodes=610, num_edges=3006)\n",
      "next(train_dataloader_iter) = DataBatch(x=[610, 500], edge_index=[2, 3006], y=[610], batch=[610], ptr=[3], test_mask=[610], train_mask=[610], val_mask=[610], num_nodes=610, num_edges=3006)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader_iter = iter(train_dataloader)\n",
    "print(f\"{next(train_dataloader_iter) = }\")\n",
    "print(f\"{next(train_dataloader_iter) = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3587482",
   "metadata": {},
   "source": [
    "As expected, we can appreciate how each mini-batch has the same number of nodes and edges that we specified earlier (610 and 3006 respectively). All the tensor shapes are consistent across mini-batches too. Now that we have clustered and loaded the data compatibly with the AOT requirements of the IPU, the next step is to train a GNN model to classify the papers in our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c6a0e7",
   "metadata": {},
   "source": [
    "### Training a GNN to classify papers in the PubMed dataset\n",
    "\n",
    "The first step is to define a GNN model to carry out our classification task. We can easily re-use one of the models we defined in the previous tutorials, for example a simple GCN-based one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23bd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(in_channels, 64)\n",
    "        self.conv2 = GCNConv(64, out_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index, mask=None, y=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        out = F.log_softmax(x, dim=-1)\n",
    "\n",
    "        if self.training:\n",
    "            target = torch.where(~mask, target, -100)\n",
    "            return out, F.nll_loss(out, target)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e8c6c9e",
   "metadata": {},
   "source": [
    "We can now create the PopTorch model and train it on the IPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8cd7d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(500, 64)\n",
       "  (conv2): GCNConv(64, 3)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(dataset.num_features, dataset.num_classes)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55598993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "poptorch_model = poptorch.trainingModel(model, optimizer=optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ad831c7",
   "metadata": {},
   "source": [
    "Training loop looks like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e88f45",
   "metadata": {},
   "source": [
    "## Neighbourhood sampling the computation graph for node classification\n",
    "\n",
    "Idea: learn how to aggregate node feature information from a node's K-hop neighbourhood, where K is the number of layers of your GNN. This means we need relatively small memory requirements: to generate the embeddings of a node I only need to know the k-hop neighbourhood structure around that node and the relative features, we don't need to store the rest of the graph. In this way, the mini-batches are going to be made of K-hop neighbourhoods. \n",
    "\n",
    "Link GraphSAGE paper (TODO add)\n",
    "\n",
    "### Neighbour sampling in PyG on IPUs \n",
    "\n",
    "Notes:\n",
    "- In PyG one would use the `NeighborLoader`: a data loader that performs neighbour sampling as per the GraphSAGE paper, allowing for mini-batching when full-batch update is not feasible. \n",
    "- On the IPU we need to deal with AOT compilation. Adam has an implementation for a `FixedSizeNeighborLoader` I can leverage, with a couple of TODOs to deal with.\n",
    "\n",
    "### Training a GNN to classify papers in the PubMed dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2bae0a",
   "metadata": {},
   "source": [
    "> ### Useful tips and known challenges\n",
    ">\n",
    "> #### Working with `argparse` and command line arguments\n",
    ">\n",
    "> If you have encountered problems related to `argparse` while writing a notebook, these tips may help you resolve your problem:\n",
    "> - Try to disentangle your application from any argument parsing logic.\n",
    "> - Manually create an [`argparse.Namespace`](https://docs.python.org/3/library/argparse.html#argparse.Namespace).\n",
    "> - Define custom parsing logic in your app to detect when its running in a Jupyter Notebook, for example as shown in the [simple parsing utilities](https://github.com/graphcore/examples-utils/blob/f8673d362fdc7dc77e1fee5f77cbcd81dd9e4a2e/examples_utils/parsing/simple_parsing_tools.py#L118). \n",
    "> \n",
    "> Often with these kinds of problems, the issue is rooted in the structure of the app, so consider using the [Applications common code interface](https://graphcore.atlassian.net/wiki/spaces/PM/pages/3164995668/Making+applications+notebook+ready+RFC#Proposal) to write an app that is easier to use.\n",
    ">\n",
    "> #### Detaching from IPUs\n",
    ">\n",
    "> Notebooks continue running after the last cell has been run, so you need to make sure that all IPUs are released at the end. This ensures that other users have resources available to run their notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d4f685f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PoptorchGCN' object has no attribute 'isAttachedToDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39;49misAttachedToDevice():\n\u001b[1;32m      2\u001b[0m     model\u001b[39m.\u001b[39mdetachFromDevice()\n",
      "File \u001b[0;32m/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:278\u001b[0m, in \u001b[0;36mPoplarExecutor.__init__.<locals>.PoptorchModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 278\u001b[0m     attribute \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)\n\u001b[1;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(attribute, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mparameter\u001b[39m.\u001b[39mParameter):\n\u001b[1;32m    280\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopyWeightsToHostIfNeeded()\n",
      "File \u001b[0;32m/localdata/ariannas/3.3.0+1326-EA.1/3.3.0+1326_poptorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PoptorchGCN' object has no attribute 'isAttachedToDevice'"
     ]
    }
   ],
   "source": [
    "if model.isAttachedToDevice():\n",
    "    model.detachFromDevice()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ece4041",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we explored the main methods to deal with large graphs that otherwise wouldn't fit in memory, using two different sampling approaches and dedicated dataloaders to optimise performance on Graphcore IPUs. While we have worked with homogeneous graphs in this tutorial, scaled up GNN problems are also very well suited to heterogeneous graphs (for example, citation graphs can be huge).\n",
    "\n",
    "TODO add more details about what we covered\n",
    "\n",
    "> This section should describe the conclusions from this notebook:\n",
    ">\n",
    "> - Summarise the main steps that were performed in the demo making it clear what\n",
    ">  your user got to do. This can be similar to the learning outcomes listed at the beginning of the notebook, but can contain more details. Try to link the specific feature, method or class that was used to achieving a specific outcome. Remember we want to highlight how we can solve the user's problems not sell a feature. (short paragraph: 3-6 sentences)\n",
    "> - Provide resources for the user's next steps. These can be links to other tutorials, to specific \n",
    ">  documentation (for example user guides, tech notes), to code examples in the public Graphcore [examples](https://github.com/graphcore/examples) repo, or to other deployments. (2-4 suggestions)\n",
    ">\n",
    "> If you want to link to a notebook in the same runtime, then point the user to the file is rather than using an explicit. For example: \"Please see our [name of tutorial] tutorial in `<folder_name>/<notebook_name>.ipynb`. For relative links, the Paperspace platform will download the file locally if the machine is running and if the machine is not running it will throw a 404 error. New windows are opened for full path links."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.3.0+1326_poptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
