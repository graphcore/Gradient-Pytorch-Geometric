{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc3a84c",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ede1575b",
   "metadata": {},
   "source": [
    "# Heterogeneous graph learning on IPUs\n",
    "\n",
    "Many real-world graphs are heterogeneous, meaning the TODO\n",
    "\n",
    "In this tutorial you will learn how to:\n",
    "\n",
    "- Use a couple of PyTorch Geometric approaches to Heterogeneous graph learning and how to run them on the IPU.\n",
    "- Understand how to sample heterogeneous graphs with a fixed size suitable for the IPU.\n",
    "\n",
    "While this tutorial will cover enough of the basics of GNNs, PyTorch Geometric and PopTorch\n",
    "for you to start developing and porting your GNN applications to the IPU;\n",
    "the following resources can be used to complement your understanding of:\n",
    "\n",
    "- PopTorch : [Introduction to PopTorch - running a simple model](https://github.com/graphcore/tutorials/tree/master/tutorials/pytorch/basics);\n",
    "- GNNs : [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n",
    "- PyTorch Geometric (PyG): [Heterogeneous Graph Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html)\n",
    "\n",
    "## Running on Paperspace\n",
    "\n",
    "The Paperspace environment lets you run this notebook with no set up. To improve your experience we preload datasets and pre-install packages, this can take a few minutes, if you experience errors immediately after starting a session please try restarting the kernel before contacting support. If a problem persists or you want to give us feedback on the content of this notebook, please reach out to through our community of developers using our [slack channel](https://www.graphcore.ai/join-community) or raise a [GitHub issue](https://github.com/graphcore/examples).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Python packages installed with `pip install -r ./requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1deed45c",
   "metadata": {},
   "source": [
    "\n",
    "In order to improve usability and support for future users, Graphcore would like to collect information about the\n",
    "applications and code being run in this notebook. The following information will be anonymised before being sent to Graphcore:\n",
    "\n",
    "- User progression through the notebook\n",
    "- Notebook details: number of cells, code being run and the output of the cells\n",
    "- Environment details\n",
    "\n",
    "You can disable logging at any time by running `%unload_ext gc_logger` from any cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99a34b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'notebook_logging' from 'examples_utils' (/nethome/adams/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/examples_utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall -q -r ./requirements.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexamples_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_logging\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_logger\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notebook_logging' from 'examples_utils' (/nethome/adams/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/examples_utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "%pip install -q -r ./requirements.txt\n",
    "from examples_utils import notebook_logging\n",
    "%load_ext gc_logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db1f0c7e",
   "metadata": {},
   "source": [
    "And for compatibility with the Paperspace environment variables we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b38c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "executable_cache_dir = (\n",
    "    os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/pyg-packing\"\n",
    ")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0fedbd3",
   "metadata": {},
   "source": [
    "Now we are ready to start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3df392b8",
   "metadata": {},
   "source": [
    "## Introduction to heterogeneous graphs\n",
    "\n",
    "Heterogeneous graphs are graphs with different types of nodes and edges. TODO\n",
    "\n",
    "TODO: Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1acd0039",
   "metadata": {},
   "source": [
    "### Loading a heterogeneous graph dataset\n",
    "\n",
    "In this tutorial we will use the [IMDB](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.IMDB.html) from PyTorch Geometric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00665e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import IMDB\n",
    "\n",
    "dataset = IMDB(root=f\"{dataset_directory}/IMDB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bdde717",
   "metadata": {},
   "source": [
    "This dataset is a single large heterogeneous graph, let's take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ccd0140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[4278, 3066],\n",
       "    y=[4278],\n",
       "    train_mask=[4278],\n",
       "    val_mask=[4278],\n",
       "    test_mask=[4278]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2953f2ed",
   "metadata": {},
   "source": [
    "Here you can see the heterogeneous graph is made up of three node types **movie**, **director** and **actor**, each with their own sets of features (`x`). These nodes are connected by two edge types, **movie to director** and **movie to actor**, with the reverse of those edges also present.\n",
    "\n",
    "The **movie** node type is the target for any training we will do, let's take a look at the labels for this node type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eaee4462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "classes = torch.unique(data[\"movie\"].y)\n",
    "num_classes = len(classes)\n",
    "classes, num_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d18abfd3",
   "metadata": {},
   "source": [
    "You can see the labels are one of three classes, these correspond to the genre of the movie, action, comedy or drama.\n",
    "\n",
    "Now we have some understanding of what a heterogeneous graph looks like in PyTorch Geometric, let's next understand how we would construct a model to be able to learn from a heterogeneous graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31bea3f5",
   "metadata": {},
   "source": [
    "## Creating Heterogeneous GNNs\n",
    "\n",
    "TODO\n",
    "\n",
    "PyTorch Geometric provides three ways to create a model for heterogeneous graph data, we will take a look at each in turn and understand any modifications to make to enable these models to run on the IPU.\n",
    "\n",
    "### Converting a GNN model\n",
    "\n",
    "The first approach we will look at is converting a PyTorch Geometric GNN model to a model for heterogeneous graphs using the `torch_geometric.nn.to_hetero()` transformation.\n",
    "\n",
    "We will only cover the basics here to enable running on the IPU, but if you are interested in learning more about this approach see the [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#automatically-converting-gnn-models).\n",
    "\n",
    "To begin with let's create a PyTorch Geometric GNN model, comprising of a couple of convolution layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a840f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), 64)\n",
    "        self.conv2 = SAGEConv((-1, -1), 64)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48ffb9d3",
   "metadata": {},
   "source": [
    "Now we can use the `to_hetero()` transformation to transform this GNN model into a heterogeneous model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c3e9da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       "  (conv2): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "# Initialize the model\n",
    "model = Model()\n",
    "# Convert the model to a heterogeneous model\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ea07404",
   "metadata": {},
   "source": [
    "You can now see that we have a convolution layer for each edge type, which has enabled this model to do message passing on a heterogeneous graph. The model will now expect a dictionary of node and edge types as inputs.\n",
    "\n",
    "Notice how we set the convolution layer `in_channels` to `-1`. This allows PyTorch Geometric to use lazy initialization based on the input dimensions, which means we don't need to manually specify the dimensions for each node type. We can then perform this lazy initialization on the CPU as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8be623d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "825dad1d",
   "metadata": {},
   "source": [
    "To run your model using PyTorch Geometric on the IPU, the model will need to target PopTorch and will require a number of changes.\n",
    "\n",
    "The first change is to move the loss function inside the `forward` method of the model. We can do this by creating a simple module that wraps the transformed heterogeneous model, that includes the loss calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef5f389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model wrapper to include the loss in the model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, target=None, train_mask=None):\n",
    "        out = self.model(x_dict, edge_index_dict)\n",
    "        # TODO: Should I project down to num_classes\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            # TODO: Is this loss function right to use for this case?\n",
    "            loss = F.cross_entropy(out['movie'], target)\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "# Include loss in model\n",
    "model = ModelWithLoss(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b27d7524",
   "metadata": {},
   "source": [
    "Now our model is ready for training with PopTorch on IPUs.\n",
    "\n",
    "In the normal way we can wrap our model in `poptorch.trainingModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffa3067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "import poptorch\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87da5309",
   "metadata": {},
   "source": [
    "And run the training loop. Note the backward pass and optimizer step is handled by PopTorch automatically so does not need to be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50211ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07abe517",
   "metadata": {},
   "source": [
    "Here we have seen how to create a heterogeneous GNN using the `to_hetero()` transformation and start training on the IPU. An alternative approach is to use the `HeteroConv` layer which we will see next."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "072f880b",
   "metadata": {},
   "source": [
    "### Using the Heterogeneous Convolution Wrapper\n",
    "\n",
    "TODO: Do same as above wrapping your model in a module with the loss function\n",
    "\n",
    "[PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#using-the-heterogeneous-convolution-wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42df98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv, Linear\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('movie', 'to', 'director'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('director', 'to', 'movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('movie', 'to', 'actor'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "                ('actor', 'to', 'movie'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self,\n",
    "                x_dict,\n",
    "                edge_index_dict,\n",
    "                target=None,\n",
    "                train_mask=None):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        out = self.lin(x_dict['movie'])\n",
    "\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "model = HeteroGNN(hidden_channels=64,\n",
    "                  out_channels=num_classes,\n",
    "                  num_layers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a860515",
   "metadata": {},
   "source": [
    "In the same way as before we set the convolution layer `in_channels` to `-1`. We can then perform the lazy initialization on the CPU again as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e370be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict,\n",
    "                data.edge_index_dict,\n",
    "                target=data['movie'].y,\n",
    "                train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30bdab47",
   "metadata": {},
   "source": [
    "We wrap the model in `poptorch.trainingModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e813684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11d40df1",
   "metadata": {},
   "source": [
    "And perform the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78715dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5999398f",
   "metadata": {},
   "source": [
    "We have now seen two approaches to creating heterogeneous GNNs ready for the IPU using PyTorch Geometric. We will next look at the final approach, using heterogeneous operators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6c5b87a",
   "metadata": {},
   "source": [
    "### Using Heterogeneous operators\n",
    "\n",
    "The final approach PyTorch Geometric provides to create a heterogeneous GNN model is to use operators specifically designed for heterogeneous graphs. These can be used as normal, taking care to do the normal steps to mentioned previously to run on IPUs: moving the loss inside the model, wrapping the model in `poptorch.trainingModel` and removing the call to the backward pass and optimizer step.\n",
    "\n",
    "See the [PyTorch Geometric Documenation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#deploy-existing-heterogeneous-operators) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4666c44b",
   "metadata": {},
   "source": [
    "## Fixed size heterogeneous data loading\n",
    "\n",
    "As real-world heterogeneous graphs can be quite large, it may often be appropriate to move from full-batch training to mini-batch training using some form of sampling. PyTorch Geometric provides a range of samplers suitable for heterogeneous graphs, for example the `NeighborLoader` which we will look at below.\n",
    "\n",
    "When moving from full-batch to mini-batch on the IPU, one must consider the sizes of the mini-batches. The IPU uses ahead-of-time compilation, which means all mini-batches must be the same size, outlined in previous tutorials (TODO). In the homogeneous graph case, making our mini-batches fixed size is relatively trivial, adding padding to make the nodes and edges up to a fixed size. This becomes more complex with heterogeneous graphs when there are different node and edge types.\n",
    "\n",
    "Let's create an instance of the PyTorch Geometric `NeighborLoader` with our dataset, and see what the first mini-batch looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0fc7924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[1172, 3066],\n",
       "    y=[1172],\n",
       "    train_mask=[1172],\n",
       "    val_mask=[1172],\n",
       "    test_mask=[1172],\n",
       "    n_id=[1172],\n",
       "    input_id=[128],\n",
       "    batch_size=128\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={\n",
       "    x=[112, 3066],\n",
       "    n_id=[112]\n",
       "  },\n",
       "  \u001b[1mactor\u001b[0m={\n",
       "    x=[329, 3066],\n",
       "    n_id=[329]\n",
       "  },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={\n",
       "    edge_index=[2, 413],\n",
       "    e_id=[413]\n",
       "  },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
       "    edge_index=[2, 1196],\n",
       "    e_id=[1196]\n",
       "  },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={\n",
       "    edge_index=[2, 128],\n",
       "    e_id=[128]\n",
       "  },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={\n",
       "    edge_index=[2, 384],\n",
       "    e_id=[384]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As normal\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[5] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48d4895a",
   "metadata": {},
   "source": [
    "To make up this mini-batch to a fixed size, we could simply pad the nodes and edges of each node and edge type to a particular value. We could manually create `poptorch_geometric.FixedSizeOptions` to do this, or we could sample from the above data loader and get an estimate on the required sizes based on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe enable this in fixed size options\n",
    "\n",
    "fixed_size_options = FixedSizeOptions.from_loader(train_loader)\n",
    "fixed_size_options"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59673ee",
   "metadata": {},
   "source": [
    "Here you can see the fixed sizes that will be appropriate for the neighbor loading. Now we can use these sizes to create a fixed size version of the `NeighborLoader` the `poptorch_geometric.FixedSizeNeighborLoader` that will do the same sampling but produce fixed size mini-batches.\n",
    "\n",
    "TODO: See sampling tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_size_train_loader = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    over_size_behaviour=OverSizeBehaviour.TRIM_NODES_AND_EDGES\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d8041f2",
   "metadata": {},
   "source": [
    "Note how we have set `over_size_behaviour=OverSizeBehaviour.TRIM_NODES_AND_EDGES`. Unfortunately we don't know ahead of time whether we have allocated enough space for the padding, therefore we can enable trimming any excess nodes from our samples in the case the mini-batches are greater than our specified sizes.\n",
    "\n",
    "There may be cases when you want to specify a different fixed size for each node and edge type, this can be done like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53573dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Different fixed size for each node and edge type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ef8759",
   "metadata": {},
   "source": [
    "The approach to achieve fixed size mini-batches for heterogeneous graphs can be achieved using the other data loaders in PopTorch Geometric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5abb611c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we have learnt how to train heterogeneous GNNs on the IPU using PyTorch Geometric.\n",
    "\n",
    "You should now have a good understanding of:\n",
    " - the approaches PyTorch Geometric provides to create heterogeneous GNN models\n",
    " - how to run the model produced by each approach on the IPU\n",
    " - how to achieve fixed size mini-batches of heterogeneous graphs suitable for the IPU.\n",
    "\n",
    "Additional resources which may help you understand Heterogeneous Graph Learning can be found in the [PyTorch Geometric documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.2.0+1277_poptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "traceability": {
   "sdk_version": "3.2.0+1262",
   "source_file": "4_small_graph_batching_with_packing.py",
   "sst_version": "0.0.10",
   "timestamp": "2023-03-13T10:16"
  },
  "vscode": {
   "interpreter": {
    "hash": "14ed74787bcb3a85d33b99e2a461605961fba8ba6d9ddfcf06c9973f1378dba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
