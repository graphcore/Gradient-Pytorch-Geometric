{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc3a84c",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ede1575b",
   "metadata": {},
   "source": [
    "# Heterogeneous graph learning on IPUs\n",
    "\n",
    "Many real-world graphs are heterogeneous, meaning single node and edge features are insufficient to capture all the information in the graph, leading to graphs which have a different node types and different edge types between those nodes. This comes with a few considerations, how do we construct a model suitable for training with heterogeneous graph data and how do we create mini-batches from this data. We will answer both of those questions, with a focus of looking at how we do these on Graphcore IPUs to enable accelerating heterogeneous graph learning workloads.\n",
    "\n",
    "In this tutorial you will learn how to:\n",
    "\n",
    "- Use a couple of PyTorch Geometric approaches to Heterogeneous graph learning and how to run them on the IPU.\n",
    "- Understand how to sample heterogeneous graphs with a fixed size suitable for the IPU.\n",
    "\n",
    "While this tutorial will cover enough of the basics of GNNs, PyTorch Geometric and PopTorch\n",
    "for you to start developing and porting your GNN applications to the IPU;\n",
    "the following resources can be used to complement your understanding of:\n",
    "\n",
    "- PopTorch : [Introduction to PopTorch - running a simple model](https://github.com/graphcore/tutorials/tree/master/tutorials/pytorch/basics);\n",
    "- GNNs : [A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)\n",
    "- PyTorch Geometric (PyG): [Heterogeneous Graph Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html)\n",
    "\n",
    "## Running on Paperspace\n",
    "\n",
    "The Paperspace environment lets you run this notebook with no set up. To improve your experience we preload datasets and pre-install packages, this can take a few minutes, if you experience errors immediately after starting a session please try restarting the kernel before contacting support. If a problem persists or you want to give us feedback on the content of this notebook, please reach out to through our community of developers using our [slack channel](https://www.graphcore.ai/join-community) or raise a [GitHub issue](https://github.com/graphcore/examples).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Python packages installed with `pip install -r ./requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1deed45c",
   "metadata": {},
   "source": [
    "\n",
    "In order to improve usability and support for future users, Graphcore would like to collect information about the\n",
    "applications and code being run in this notebook. The following information will be anonymised before being sent to Graphcore:\n",
    "\n",
    "- User progression through the notebook\n",
    "- Notebook details: number of cells, code being run and the output of the cells\n",
    "- Environment details\n",
    "\n",
    "You can disable logging at any time by running `%unload_ext gc_logger` from any cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c085fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imported python modules automatically reload when the files are changed\n",
    "# needs to be before the first import.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# TODO: remove at the end of notebook development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a34b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: failed to access '/root/.ipython/extensions': Permission denied\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gc_logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall -q -r ./requirements.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexamples_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_logging\n\u001b[0;32m----> 3\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mload_ext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgc_logger\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mextension_manager\u001b[39m.\u001b[39;49mload_extension(module_str)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_extension(module_str)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/IPython/core/extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[0;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[1;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m/usr/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:973\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gc_logger'"
     ]
    }
   ],
   "source": [
    "%pip install -q -r ./requirements.txt\n",
    "from examples_utils import notebook_logging\n",
    "%load_ext gc_logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db1f0c7e",
   "metadata": {},
   "source": [
    "And for compatibility with the Paperspace environment variables we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b38c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "executable_cache_dir = (\n",
    "    os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/pyg-packing\"\n",
    ")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0fedbd3",
   "metadata": {},
   "source": [
    "Now we are ready to start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3df392b8",
   "metadata": {},
   "source": [
    "## Introduction to heterogeneous graphs\n",
    "\n",
    "Heterogeneous graphs are graphs with different types of nodes and edges, appropriate when having a single node or edge feature for the whole graph doesn't capture all the information of the graph, for example because different nodes have a different amount of features. Let's first load a heterogeneous graph dataset from PyTorch Geometric and then go on to see how the construction of the model differs when dealing with heterogeneous graph data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1acd0039",
   "metadata": {},
   "source": [
    "### Loading a heterogeneous graph dataset\n",
    "\n",
    "In this tutorial we will use the [IMDB](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.IMDB.html) from PyTorch Geometric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00665e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import IMDB\n",
    "\n",
    "dataset = IMDB(root=f\"{dataset_directory}/IMDB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bdde717",
   "metadata": {},
   "source": [
    "This dataset is a single large heterogeneous graph,made up of three node types **movie**, **director** and **actor**, each with their own sets of features (`x`). These nodes are connected by two edge types, **movie to director** and **movie to actor**, with the reverse of those edges also present.\n",
    "\n",
    "![IMDB_dataset.jpg](static/IMDB_dataset.jpg)\n",
    "\n",
    "let's take a look at it in PyTorch Geometric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd0140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[4278, 3066],\n",
       "    y=[4278],\n",
       "    train_mask=[4278],\n",
       "    val_mask=[4278],\n",
       "    test_mask=[4278]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2953f2ed",
   "metadata": {},
   "source": [
    "The **movie** node type is the target for any training we will do. Taking a look at the labels you can see they are one of three classes, these correspond to the genre of the movie, action, comedy or drama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaee4462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "classes = torch.unique(data[\"movie\"].y)\n",
    "num_classes = len(classes)\n",
    "classes, num_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d130750",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we will select only a fraction of this dataset. We will cover proper sampling approaches in the `Fixed size heterogeneous data loading` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "def95891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[1000, 3066],\n",
       "    y=[1000],\n",
       "    train_mask=[1000],\n",
       "    val_mask=[1000],\n",
       "    test_mask=[1000]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[482, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[1469, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 2998] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 1000] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 2998] }\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import RemoveIsolatedNodes\n",
    "\n",
    "data = data.subgraph({\"movie\": torch.arange(0, 1000)})\n",
    "data = RemoveIsolatedNodes()(data)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d18abfd3",
   "metadata": {},
   "source": [
    "Now we have some understanding of what a heterogeneous graph looks like in PyTorch Geometric, let's next understand how we would construct a model to be able to learn from a heterogeneous graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31bea3f5",
   "metadata": {},
   "source": [
    "## Creating Heterogeneous GNNs\n",
    "\n",
    "PyTorch Geometric provides three ways to create a model for heterogeneous graph data, we will take a look at each in turn and understand any modifications to make to enable these models to run on the IPU. Each approach is taken from the [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html). Here we will cover the changes when enabling running these approaches on the IPU. For more detail on the approaches themselves we recommend reading the documentation directly.\n",
    "\n",
    "### Converting a GNN model\n",
    "\n",
    "The first approach we will look at is converting a PyTorch Geometric GNN model to a model for heterogeneous graphs using the `torch_geometric.nn.to_hetero()` transformation.\n",
    "\n",
    "We will only cover the basics here to enable running on the IPU, but if you are interested in learning more about this approach see the [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#automatically-converting-gnn-models).\n",
    "\n",
    "To begin with let's create a PyTorch Geometric GNN model, comprising of a couple of convolution layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a840f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), 64)\n",
    "        self.conv2 = SAGEConv((-1, -1), 64)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48ffb9d3",
   "metadata": {},
   "source": [
    "Now we can use the `to_hetero()` transformation to transform this GNN model into a heterogeneous model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3e9da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       "  (conv2): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "# Initialize the model\n",
    "model = Model()\n",
    "# Convert the model to a heterogeneous model\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ea07404",
   "metadata": {},
   "source": [
    "You can now see that we have a convolution layer for each edge type, which has enabled this model to do message passing on a heterogeneous graph. The model will now expect a dictionary of node and edge types as inputs.\n",
    "\n",
    "Notice how we set the convolution layer `in_channels` to `-1`. This allows PyTorch Geometric to use lazy initialization based on the input dimensions, which means we don't need to manually specify the dimensions for each node type. We can then perform this lazy initialization on the CPU as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8be623d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "825dad1d",
   "metadata": {},
   "source": [
    "To run your model using PyTorch Geometric on the IPU, the model will need to target PopTorch and will require a number of changes.\n",
    "\n",
    "The first change is to move the loss function inside the `forward` method of the model. We can do this by creating a simple module that wraps the transformed heterogeneous model, that includes the loss calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef5f389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, target=None, train_mask=None):\n",
    "        out = self.model(x_dict, edge_index_dict)\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            loss = F.cross_entropy(out['movie'], target)\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "# Include loss in model\n",
    "model = ModelWithLoss(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b27d7524",
   "metadata": {},
   "source": [
    "Now our model is ready for training with PopTorch on IPUs.\n",
    "\n",
    "In the normal way we can wrap our model in `poptorch.trainingModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffa3067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch\n",
    "\n",
    "# Set up training\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87da5309",
   "metadata": {},
   "source": [
    "And run the training loop. Note the backward pass and optimizer step is handled by PopTorch automatically so does not need to be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50211ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.0003)\n",
      "loss = tensor(0.0002)\n",
      "loss = tensor(9.7318e-05)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)\n",
    "    print(f\"{loss = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07abe517",
   "metadata": {},
   "source": [
    "Here we have seen how to create a heterogeneous GNN using the `to_hetero()` transformation and start training on the IPU. An alternative approach is to use the `HeteroConv` layer which we will see next."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "072f880b",
   "metadata": {},
   "source": [
    "### Using the Heterogeneous Convolution Wrapper\n",
    "\n",
    "Another approach to doing heterogeneous graphs with PyTorch Geometric is to use the `torch_geometric.nn.HeteroConv` layer. This gives more flexibility than the above approach allowing each edge type to use a different message passing layer. For more details on this approach, see the [PyTorch Geometric Documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#using-the-heterogeneous-convolution-wrapper).\n",
    "\n",
    "Now let's take the steps to enable using this approach for the IPU. As normal we first move the loss function within the model, passing the mask and labels to the `forward` method. Below you can see a simple model using the `HeteroConv` layer with the loss function moved inside the `forward` method, ready for running on the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42df98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv, Linear\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('movie', 'to', 'director'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('director', 'to', 'movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('movie', 'to', 'actor'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "                ('actor', 'to', 'movie'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self,\n",
    "                x_dict,\n",
    "                edge_index_dict,\n",
    "                target=None,\n",
    "                train_mask=None):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        out = self.lin(x_dict['movie'])\n",
    "\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "model = HeteroGNN(hidden_channels=64,\n",
    "                  out_channels=num_classes,\n",
    "                  num_layers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a860515",
   "metadata": {},
   "source": [
    "In the same way as before we set the convolution layer `in_channels` to `-1`. We can then perform the lazy initialization on the CPU again as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e370be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict,\n",
    "                data.edge_index_dict,\n",
    "                target=data['movie'].y,\n",
    "                train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30bdab47",
   "metadata": {},
   "source": [
    "We wrap the model in `poptorch.trainingModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e813684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11d40df1",
   "metadata": {},
   "source": [
    "And perform the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78715dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.5073)\n",
      "loss = tensor(0.3215)\n",
      "loss = tensor(0.1516)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)\n",
    "    print(f\"{loss = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5999398f",
   "metadata": {},
   "source": [
    "We have now seen two approaches to creating heterogeneous GNNs ready for the IPU using PyTorch Geometric. We will next look at the final approach, using heterogeneous operators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6c5b87a",
   "metadata": {},
   "source": [
    "### Using Heterogeneous operators\n",
    "\n",
    "The final approach PyTorch Geometric provides to create a heterogeneous GNN model is to use operators specifically designed for heterogeneous graphs. These layers can be used as normal, taking care to do the normal steps mentioned previously to enable running on IPUs: moving the loss inside the model, wrapping the model in `poptorch.trainingModel` and removing the call to the backward pass and optimizer step.\n",
    "\n",
    "See the [PyTorch Geometric Documenation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html#deploy-existing-heterogeneous-operators) for more information on this approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4666c44b",
   "metadata": {},
   "source": [
    "## Fixed size heterogeneous data loading\n",
    "\n",
    "As real-world heterogeneous graphs can be quite large, it may often be appropriate to move from full-batch training to mini-batch training using some form of sampling. PyTorch Geometric provides a range of samplers suitable for heterogeneous graphs, for example the `NeighborLoader` which we will look at below.\n",
    "\n",
    "When moving from full-batch to mini-batch on the IPU, one must consider the sizes of the mini-batches. The IPU uses ahead-of-time compilation, which means all mini-batches must be the same size, outlined in previous tutorials (TODO). In the homogeneous graph case, making our mini-batches fixed size is relatively trivial, adding padding to make the nodes and edges up to a fixed size. This becomes more complex with heterogeneous graphs when there are different node and edge types.\n",
    "\n",
    "Let's create an instance of the PyTorch Geometric `NeighborLoader` with our dataset, and see what the first mini-batch looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0fc7924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/adams/venvs/3.3.0+1361-EA.2/3.3.0+1361_poptorch/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:58: UserWarning: Using '{self.__class__.__name__}' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[486, 3066],\n",
       "    y=[486],\n",
       "    train_mask=[486],\n",
       "    val_mask=[486],\n",
       "    test_mask=[486],\n",
       "    n_id=[486],\n",
       "    input_id=[87],\n",
       "    batch_size=87\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={\n",
       "    x=[77, 3066],\n",
       "    n_id=[77]\n",
       "  },\n",
       "  \u001b[1mactor\u001b[0m={\n",
       "    x=[227, 3066],\n",
       "    n_id=[227]\n",
       "  },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={\n",
       "    edge_index=[2, 212],\n",
       "    e_id=[212]\n",
       "  },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
       "    edge_index=[2, 596],\n",
       "    e_id=[596]\n",
       "  },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={\n",
       "    edge_index=[2, 87],\n",
       "    e_id=[87]\n",
       "  },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={\n",
       "    edge_index=[2, 261],\n",
       "    e_id=[261]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As normal\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[5] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48d4895a",
   "metadata": {},
   "source": [
    "To make up this mini-batch to a fixed size, we could simply pad the nodes and edges of each node and edge type to a particular value. We have seen in other tutorials how we can make a mini-batch fixed size for homogeneous graphs, for example in the case of neighbor loading see TODO. For heterogeneous graphs we have some additional considerations to make. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dda19c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedSizeOptions(num_nodes=1000 (At least one node reserved for padding), num_edges=1000 (At least one edge reserved for padding), num_graphs=2 (At least one graph reserved for padding), node_pad_value=0.0, edge_pad_value=0.0, graph_pad_value=0.0, pad_graph_defaults={})\n"
     ]
    }
   ],
   "source": [
    "from poptorch_geometric import FixedSizeOptions\n",
    "\n",
    "fixed_size_options = FixedSizeOptions(\n",
    "    num_nodes=1000,\n",
    "    num_edges=1000,\n",
    ")\n",
    "print(fixed_size_options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59673ee",
   "metadata": {},
   "source": [
    "Here you can see the fixed sizes that will be appropriate for the neighbor loading. Now we can use these sizes to create a fixed size version of the `NeighborLoader` the `poptorch_geometric.FixedSizeNeighborLoader` that will do the same sampling but produce fixed size mini-batches.\n",
    "\n",
    "TODO: See sampling tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poptorch_geometric import FixedSizeNeighborLoader, OverSizeStrategy\n",
    "\n",
    "\n",
    "fixed_size_train_loader = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    over_size_behaviour=OverSizeStrategy.TRIM_NODES_AND_EDGES\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d8041f2",
   "metadata": {},
   "source": [
    "You can see that now the nodes and edges of each node and edge type are the same size and so suitable for using with the IPU.\n",
    "\n",
    "Note how we have set `over_size_behaviour=OverSizeBehaviour.TRIM_NODES_AND_EDGES`. Unfortunately we don't know ahead of time whether we have allocated enough space for the padding, therefore we can enable trimming any excess nodes from our samples in the case the mini-batches are greater than our specified sizes.\n",
    "\n",
    "There may be a lot of wasted space in this mini-batch as we have set the same number of nodes and edges to pad to for all node and edge types. We can be more specific and set a different number for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53573dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_size_options = FixedSizeOptions(\n",
    "    num_nodes={\n",
    "        \"movies\": 500,\n",
    "        \"directors\": 100,\n",
    "        \"actors\": 300\n",
    "    },\n",
    "    num_edges={\n",
    "        (\"movies\", \"to\", \"directors\"): 100,\n",
    "        (\"movies\", \"to\", \"actors\"): 200,\n",
    "        (\"directors\", \"to\", \"movies\"): 100,\n",
    "        (\"actors\", \"to\", \"movies\"): 200,\n",
    "    }\n",
    ")\n",
    "print(fixed_size_options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6a72dd4",
   "metadata": {},
   "source": [
    "This can become quite complex so instead we can use the original non-fixed-size neighbour loader to give us an estimate of the fixed size options suitable for this loader. This will sample from the non-fixed-size loader, and produce fixed-size options which will have different numbers of nodes and edges to pad to for each node and edge type. This can help make your mini-batches contain less padded nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enable this in fixed size options\n",
    "\n",
    "fixed_size_options = FixedSizeOptions.from_loader(train_loader)\n",
    "print(fixed_size_options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffb4d2c4",
   "metadata": {},
   "source": [
    "And use this to create the `FixedSizeNeighborLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_size_train_loader = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    over_size_behaviour=OverSizeStrategy.TRIM_NODES_AND_EDGES\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ef8759",
   "metadata": {},
   "source": [
    "Again, you can see the mini-batches produced are fixed size and so suitable for using with the IPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5abb611c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we have learnt how to train heterogeneous GNNs on the IPU using PyTorch Geometric.\n",
    "\n",
    "You should now have a good understanding of:\n",
    " - the approaches PyTorch Geometric provides to create heterogeneous GNN models\n",
    " - how to run the model produced by each approach on the IPU\n",
    " - how to achieve fixed size mini-batches of heterogeneous graphs suitable for the IPU.\n",
    "\n",
    "Additional resources which may help you understand Heterogeneous Graph Learning can be found in the [PyTorch Geometric documentation](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.2.0+1277_poptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "traceability": {
   "sdk_version": "3.2.0+1262",
   "source_file": "4_small_graph_batching_with_packing.py",
   "sst_version": "0.0.10",
   "timestamp": "2023-03-13T10:16"
  },
  "vscode": {
   "interpreter": {
    "hash": "14ed74787bcb3a85d33b99e2a461605961fba8ba6d9ddfcf06c9973f1378dba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
