{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc3a84c",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ede1575b",
   "metadata": {},
   "source": [
    "# Heterogeneous graph learning on IPUs\n",
    "\n",
    "TODO: Do intro\n",
    "\n",
    "## Running on Paperspace\n",
    "\n",
    "The Paperspace environment lets you run this notebook with no set up. To improve your experience we preload datasets and pre-install packages, this can take a few minutes, if you experience errors immediately after starting a session please try restarting the kernel before contacting support. If a problem persists or you want to give us feedback on the content of this notebook, please reach out to through our community of developers using our [slack channel](https://www.graphcore.ai/join-community) or raise a [GitHub issue](https://github.com/graphcore/examples).\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* Python packages installed with `pip install -r ./requirements.txt`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1deed45c",
   "metadata": {},
   "source": [
    "\n",
    "In order to improve usability and support for future users, Graphcore would like to collect information about the\n",
    "applications and code being run in this notebook. The following information will be anonymised before being sent to Graphcore:\n",
    "\n",
    "- User progression through the notebook\n",
    "- Notebook details: number of cells, code being run and the output of the cells\n",
    "- Environment details\n",
    "\n",
    "You can disable logging at any time by running `%unload_ext gc_logger` from any cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99a34b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'notebook_logging' from 'examples_utils' (/nethome/adams/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/examples_utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall -q -r ./requirements.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexamples_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_logging\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_logger\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notebook_logging' from 'examples_utils' (/nethome/adams/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/examples_utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "%pip install -q -r ./requirements.txt\n",
    "from examples_utils import notebook_logging\n",
    "%load_ext gc_logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db1f0c7e",
   "metadata": {},
   "source": [
    "And for compatibility with the Paperspace environment variables we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b38c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "executable_cache_dir = (\n",
    "    os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/pyg-packing\"\n",
    ")\n",
    "dataset_directory = os.getenv(\"DATASETS_DIR\", \"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0fedbd3",
   "metadata": {},
   "source": [
    "Now we are ready to start!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3df392b8",
   "metadata": {},
   "source": [
    "## Introduction to heterogeneous graphs\n",
    "\n",
    "TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1acd0039",
   "metadata": {},
   "source": [
    "### Loading TODO dataset\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00665e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/g0btk9ctr1es39x/IMDB_processed.zip?dl=1\n",
      "Extracting data/IMDB/raw/IMDB_processed.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import IMDB\n",
    "\n",
    "dataset = IMDB(root=f\"{dataset_directory}/IMDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccd0140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[4278, 3066],\n",
       "    y=[4278],\n",
       "    train_mask=[4278],\n",
       "    val_mask=[4278],\n",
       "    test_mask=[4278]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eaee4462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Movie has three categories: (action, comedy, drama)\n",
    "classes = torch.unique(data[\"movie\"].y)\n",
    "num_classes = len(classes)\n",
    "classes, num_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31bea3f5",
   "metadata": {},
   "source": [
    "## Creating Heterogeneous GNNs\n",
    "\n",
    "TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45e5b3d2",
   "metadata": {},
   "source": [
    "### Converting a homogeneous model\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a840f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), 64)\n",
    "        self.conv2 = SAGEConv((-1, -1), 64)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3e9da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       "  (conv2): ModuleDict(\n",
       "    (movie__to__director): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (movie__to__actor): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (director__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (actor__to__movie): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "# Initialize the model\n",
    "model = Model()\n",
    "# Convert the model to a heterogeneous model\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8be623d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef5f389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model wrapper to include the loss in the model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, target=None, train_mask=None):\n",
    "        out = self.model(x_dict, edge_index_dict)\n",
    "        # TODO: Should I project down to num_classes\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            # TODO: Is this loss function right to use for this case?\n",
    "            loss = F.cross_entropy(out['movie'], target)\n",
    "            return out, loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4a71df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include loss in model\n",
    "model = ModelWithLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffa3067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "import poptorch\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50211ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:22:26.931] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[11:22:26.932] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[11:22:26.995] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 639\n",
      "[11:22:26.995] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 640\n",
      "[11:22:26.996] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 641\n",
      "[11:22:26.996] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 642\n",
      "[11:22:26.996] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 643\n",
      "Graph compilation:   0%|          | 0/100 [00:00<?]2023-05-16T11:22:27.656842Z popart:popart 73541.73541 E: Failure in ReshapeOp::setup() for Op(model/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[model/director__to__movie/aggr_module/Max:0], outputs=[model/director__to__movie/aggr_module/Reshape:0/1]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\n",
      "\n",
      "[0] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n",
      "[1] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n",
      "[2] popart::Ir::constructForwards()\n",
      "[3] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n",
      "[4] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n",
      "[5] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n",
      "[6] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n",
      "[7] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n",
      "\n",
      "\n",
      "\n",
      "Graph compilation:   0%|          | 0/100 [00:00<?]\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "In unknown:0: 'popart_exception': Failure in ReshapeOp::setup() for Op(model/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[model/director__to__movie/aggr_module/Max:0], outputs=[model/director__to__movie/aggr_module/Reshape:0/1]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\nError raised in:\n  [0] popart::TrainingSession::createFromOnnxModel\n  [1] Compiler::initSession\n  [2] LowerToPopart::compile\n  [3] compileWithManualTracing\n  [4] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n  [5] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n  [6] popart::Ir::constructForwards()\n  [7] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [8] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [9] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n  [10] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  [11] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     out, loss \u001b[39m=\u001b[39m poptorch_model(data\u001b[39m.\u001b[39;49mx_dict,\n\u001b[1;32m      4\u001b[0m                                data\u001b[39m.\u001b[39;49medge_index_dict,\n\u001b[1;32m      5\u001b[0m                                target\u001b[39m=\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mmovie\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49my,\n\u001b[1;32m      6\u001b[0m                                train_mask\u001b[39m=\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mmovie\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain_mask)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:1162\u001b[0m, in \u001b[0;36mPoplarExecutor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m in_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_parser(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled())\n\u001b[1;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m-> 1162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile(in_tensors)\n\u001b[1;32m   1164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_attached:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattachToDevice()\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_impl.py:358\u001b[0m, in \u001b[0;36mtraceMethod.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    357\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profiling\u001b[39m.\u001b[39mtracepoint(label):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:922\u001b[0m, in \u001b[0;36mPoplarExecutor._compile\u001b[0;34m(self, in_tensors)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39m# In distributed execution mode:\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39m# At that point only the first process will have a compiled executable:\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[39m# trigger the compilation process in all the other processes.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m--> 922\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compileWithDispatch(in_tensors_trace_view)\n\u001b[1;32m    924\u001b[0m \u001b[39m# Load the engine and connect the streams in all the processes.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m# Note: no sync point was added because we expect the above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m# to enable executable caching to avoid out of memory issues due\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m# to concurrent compilation processes.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mconnection_type \u001b[39m!=\u001b[39m enums\u001b[39m.\u001b[39mConnectionType\u001b[39m.\u001b[39mNever:\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_impl.py:164\u001b[0m, in \u001b[0;36mdestroyDispatcherOnExit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    163\u001b[0m     \u001b[39mwith\u001b[39;00m OnExit():\n\u001b[0;32m--> 164\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:883\u001b[0m, in \u001b[0;36mPoplarExecutor._compileWithDispatch\u001b[0;34m(self, in_tensors, executable_filename)\u001b[0m\n\u001b[1;32m    876\u001b[0m         executable \u001b[39m=\u001b[39m poptorch_core\u001b[39m.\u001b[39mprocessDispatchAndImportExecutable(\n\u001b[1;32m    877\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mtoDict(), accessAttributes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training,\n\u001b[1;32m    878\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict_optimizer,\n\u001b[1;32m    879\u001b[0m             \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39manchored_tensors\u001b[39m.\u001b[39mvalues()),\n\u001b[1;32m    880\u001b[0m             executable_filename)\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m         \u001b[39m# Compile the captured graph using PopART.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m         executable \u001b[39m=\u001b[39m poptorch_core\u001b[39m.\u001b[39;49mcompileWithManualTracing(\n\u001b[1;32m    884\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options\u001b[39m.\u001b[39;49mtoDict(), accessAttributes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_training,\n\u001b[1;32m    885\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_optimizer,\n\u001b[1;32m    886\u001b[0m             \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options\u001b[39m.\u001b[39;49manchored_tensors\u001b[39m.\u001b[39;49mvalues()))\n\u001b[1;32m    888\u001b[0m \u001b[39mreturn\u001b[39;00m executable\n",
      "\u001b[0;31mError\u001b[0m: In unknown:0: 'popart_exception': Failure in ReshapeOp::setup() for Op(model/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[model/director__to__movie/aggr_module/Max:0], outputs=[model/director__to__movie/aggr_module/Reshape:0/1]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\nError raised in:\n  [0] popart::TrainingSession::createFromOnnxModel\n  [1] Compiler::initSession\n  [2] LowerToPopart::compile\n  [3] compileWithManualTracing\n  [4] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n  [5] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n  [6] popart::Ir::constructForwards()\n  [7] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [8] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [9] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n  [10] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  [11] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "072f880b",
   "metadata": {},
   "source": [
    "### Using the Heterogeneous Convolution Wrapper\n",
    "\n",
    "TODO: Do same as above wrapping your model in a module with the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42df98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv, Linear\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('movie', 'to', 'director'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('director', 'to', 'movie'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('movie', 'to', 'actor'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "                ('actor', 'to', 'movie'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self,\n",
    "                x_dict,\n",
    "                edge_index_dict,\n",
    "                target=None,\n",
    "                train_mask=None):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        out = self.lin(x_dict['movie'])\n",
    "\n",
    "        if self.training:\n",
    "            target = torch.where(train_mask, target, -100)\n",
    "            loss = F.cross_entropy(out, target)\n",
    "            return out, loss\n",
    "        return out\n",
    "\n",
    "model = HeteroGNN(hidden_channels=64,\n",
    "                  out_channels=num_classes,\n",
    "                  num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e370be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy modules.\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict,\n",
    "                data.edge_index_dict,\n",
    "                target=data['movie'].y,\n",
    "                train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e813684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "import poptorch\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Initialise model and convert the model to a poptorch model\n",
    "opts = poptorch.Options().enableExecutableCaching(executable_cache_dir)\n",
    "optim = poptorch.optim.Adam(model.parameters(), lr=0.01)\n",
    "poptorch_model = poptorch.trainingModel(model, options=opts, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78715dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:29:38.937] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[11:29:38.938] [poptorch::python] [warning] Dicts as inputs only have partial support, they can be accessed using literal keys, but full Python functionality is not enabled. Consider changing dict inputs to tuple.\n",
      "[11:29:39.012] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 942\n",
      "[11:29:39.013] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 943\n",
      "[11:29:39.013] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 944\n",
      "[11:29:39.013] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 945\n",
      "[11:29:39.013] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 946\n",
      "[11:29:39.022] [poptorch:cpp] [warning] [DISPATCHER] Tensor (ptr 0x1a585470) type coerced from Double to Float\n",
      "[11:29:39.032] [poptorch:cpp] [warning] [DISPATCHER] Tensor (ptr 0x1ab33140) type coerced from Double to Float\n",
      "[11:29:39.043] [poptorch:cpp] [warning] [DISPATCHER] Tensor (ptr 0x10fa2150) type coerced from Double to Float\n",
      "[11:29:39.052] [poptorch:cpp] [warning] [DISPATCHER] Tensor (ptr 0x1a88f8d0) type coerced from Double to Float\n",
      "Graph compilation:   0%|          | 0/100 [00:00<?]2023-05-16T11:29:39.830384Z popart:popart 73541.73541 E: Failure in ReshapeOp::setup() for Op(1/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[1/director__to__movie/aggr_module/Max:0], outputs=[1/director__to__movie/aggr_module/Reshape:0]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\n",
      "\n",
      "[0] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n",
      "[1] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n",
      "[2] popart::Ir::constructForwards()\n",
      "[3] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n",
      "[4] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n",
      "[5] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n",
      "[6] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n",
      "[7] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n",
      "\n",
      "\n",
      "\n",
      "Graph compilation:   0%|          | 0/100 [00:00<?]\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "In unknown:0: 'popart_exception': Failure in ReshapeOp::setup() for Op(1/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[1/director__to__movie/aggr_module/Max:0], outputs=[1/director__to__movie/aggr_module/Reshape:0]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\nError raised in:\n  [0] popart::TrainingSession::createFromOnnxModel\n  [1] Compiler::initSession\n  [2] LowerToPopart::compile\n  [3] compileWithManualTracing\n  [4] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n  [5] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n  [6] popart::Ir::constructForwards()\n  [7] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [8] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [9] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n  [10] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  [11] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     out, loss \u001b[39m=\u001b[39m poptorch_model(data\u001b[39m.\u001b[39;49mx_dict,\n\u001b[1;32m      4\u001b[0m                                data\u001b[39m.\u001b[39;49medge_index_dict,\n\u001b[1;32m      5\u001b[0m                                target\u001b[39m=\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mmovie\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49my,\n\u001b[1;32m      6\u001b[0m                                train_mask\u001b[39m=\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mmovie\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain_mask)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:1162\u001b[0m, in \u001b[0;36mPoplarExecutor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m in_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_parser(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled())\n\u001b[1;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m-> 1162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile(in_tensors)\n\u001b[1;32m   1164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_attached:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattachToDevice()\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_impl.py:358\u001b[0m, in \u001b[0;36mtraceMethod.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    357\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profiling\u001b[39m.\u001b[39mtracepoint(label):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:922\u001b[0m, in \u001b[0;36mPoplarExecutor._compile\u001b[0;34m(self, in_tensors)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39m# In distributed execution mode:\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39m# At that point only the first process will have a compiled executable:\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[39m# trigger the compilation process in all the other processes.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m--> 922\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compileWithDispatch(in_tensors_trace_view)\n\u001b[1;32m    924\u001b[0m \u001b[39m# Load the engine and connect the streams in all the processes.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m# Note: no sync point was added because we expect the above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m# to enable executable caching to avoid out of memory issues due\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m# to concurrent compilation processes.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mconnection_type \u001b[39m!=\u001b[39m enums\u001b[39m.\u001b[39mConnectionType\u001b[39m.\u001b[39mNever:\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_impl.py:164\u001b[0m, in \u001b[0;36mdestroyDispatcherOnExit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    163\u001b[0m     \u001b[39mwith\u001b[39;00m OnExit():\n\u001b[0;32m--> 164\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venvs/3.2.0+1277/3.2.0+1277_poptorch/lib/python3.8/site-packages/poptorch/_poplar_executor.py:883\u001b[0m, in \u001b[0;36mPoplarExecutor._compileWithDispatch\u001b[0;34m(self, in_tensors, executable_filename)\u001b[0m\n\u001b[1;32m    876\u001b[0m         executable \u001b[39m=\u001b[39m poptorch_core\u001b[39m.\u001b[39mprocessDispatchAndImportExecutable(\n\u001b[1;32m    877\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mtoDict(), accessAttributes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training,\n\u001b[1;32m    878\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dict_optimizer,\n\u001b[1;32m    879\u001b[0m             \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39manchored_tensors\u001b[39m.\u001b[39mvalues()),\n\u001b[1;32m    880\u001b[0m             executable_filename)\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m         \u001b[39m# Compile the captured graph using PopART.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m         executable \u001b[39m=\u001b[39m poptorch_core\u001b[39m.\u001b[39;49mcompileWithManualTracing(\n\u001b[1;32m    884\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options\u001b[39m.\u001b[39;49mtoDict(), accessAttributes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_training,\n\u001b[1;32m    885\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_optimizer,\n\u001b[1;32m    886\u001b[0m             \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options\u001b[39m.\u001b[39;49manchored_tensors\u001b[39m.\u001b[39;49mvalues()))\n\u001b[1;32m    888\u001b[0m \u001b[39mreturn\u001b[39;00m executable\n",
      "\u001b[0;31mError\u001b[0m: In unknown:0: 'popart_exception': Failure in ReshapeOp::setup() for Op(1/director__to__movie/aggr_module/Reshape (ai.onnx.Reshape:5), inputs=[1/director__to__movie/aggr_module/Max:0], outputs=[1/director__to__movie/aggr_module/Reshape:0]). Trying to reshape from [4278] to [2081 1]. The number of elements of the input is 4278, while the number of elements of the output is 2081. The number of elements cannot change for a ReshapeOp\nError raised in:\n  [0] popart::TrainingSession::createFromOnnxModel\n  [1] Compiler::initSession\n  [2] LowerToPopart::compile\n  [3] compileWithManualTracing\n  [4] popart::Graph::constructFromOnnxGraph(onnx::GraphProto const&)\n  [5] popart::Ir::constructFromOnnxGraph(onnx::GraphProto const&, popart::Scope const&)\n  [6] popart::Ir::constructForwards()\n  [7] popart::Ir::prepareImpl(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [8] popart::Ir::prepare(popart::IrBundle const&, std::map<unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<unsigned long>, std::allocator<std::pair<unsigned long const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > const&, unsigned long)\n  [9] popart::Session::configureFromOnnx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const*, popart::InputShapeInfo const&, std::shared_ptr<popart::DeviceInfo>, popart::SessionOptions const&, popart::Patterns const&)\n  [10] popart::TrainingSession::createFromOnnxModel(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::DataFlow const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, popart::Optimizer const&, std::shared_ptr<popart::DeviceInfo>, popart::InputShapeInfo const&, popart::SessionOptions const&, popart::Patterns const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  [11] poptorch::popart_compiler::Compiler::initSession(std::vector<poptorch::popart_compiler::Optimizer, std::allocator<poptorch::popart_compiler::Optimizer> > const&, char const*)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for _ in range(3):\n",
    "    out, loss = poptorch_model(data.x_dict,\n",
    "                               data.edge_index_dict,\n",
    "                               target=data['movie'].y,\n",
    "                               train_mask=data['movie'].train_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6c5b87a",
   "metadata": {},
   "source": [
    "### Using Heterogeneous operators\n",
    "\n",
    "TODO: These should just work as normal, ensure to include your loss in the model description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4666c44b",
   "metadata": {},
   "source": [
    "## Fixed size heterogeneous data loading\n",
    "\n",
    "TODO: Supports the same stuff as the fixed size homogeneous data loaders\n",
    "\n",
    "TODO: Demonstrate fixed size neighbour loader with heterogeneous graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As normal\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15] * 2,\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    ")\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_size_options = FixedSizeOptions.from_loader(train_loader)\n",
    "fixed_size_options"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bba917",
   "metadata": {},
   "source": [
    "TODO: Mention TRIM_NODES_AND_EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_size_train_loader = FixedSizeNeighborLoader(\n",
    "    data,\n",
    "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "    num_neighbors=[15] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes of type \"movie\":\n",
    "    batch_size=128,\n",
    "    input_nodes=('movie', data['movie'].train_mask),\n",
    "    fixed_size_options=fixed_size_options,\n",
    "    over_size_behaviour=OverSizeBehaviour.TRIM_NODES_AND_EDGES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30ff74d2",
   "metadata": {},
   "source": [
    "TODO: Can be useful to set the number of neighbours for each edge type to balance your samples and waste less space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5abb611c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.2.0+1277_poptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "traceability": {
   "sdk_version": "3.2.0+1262",
   "source_file": "4_small_graph_batching_with_packing.py",
   "sst_version": "0.0.10",
   "timestamp": "2023-03-13T10:16"
  },
  "vscode": {
   "interpreter": {
    "hash": "14ed74787bcb3a85d33b99e2a461605961fba8ba6d9ddfcf06c9973f1378dba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
